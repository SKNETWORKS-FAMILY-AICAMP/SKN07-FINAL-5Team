{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b561eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PDF 텍스트 추출\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b45c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "CHROMA_HOST = os.getenv(\"CHROMA_HOST\")\n",
    "CHROMA_PORT = os.getenv(\"CHROMA_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/job_opening.csv')\n",
    "rec_df = pd.read_csv('../data_backup/rec_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d16931",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6816ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 코드가 분당 토큰 100만을 넘겼기에 사용\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 500\n",
    "batch_documents = [documents[i:i+batch_size] for i in range(0, len(documents), batch_size)]\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectordb = None\n",
    "\n",
    "for i, batch in enumerate(batch_documents):\n",
    "    print(f\"▶ Processing batch {i+1}/{len(batch_documents)}...\")\n",
    "    if i == 0:\n",
    "        vectordb = Chroma.from_documents(\n",
    "            documents=batch,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=\"./chroma_data\",\n",
    "            collection_name=\"chroma_test\"\n",
    "        )\n",
    "    else:\n",
    "        vectordb.add_documents(batch)\n",
    "\n",
    "    vectordb.persist()\n",
    "    sleep(65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d2f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 이력서 (Resume)\n",
      "[기본 정보]\n",
      "이름: 홍길동\n",
      "연락처: 010-1234-5678\n",
      "이메일: honggildong.ai@gmail.com\n",
      "주소: 서울특별시 강남구 테헤란로 123\n",
      "[학력]\n",
      "고려대학교 컴퓨터학과 졸업 (2018.03 ~ 2024.02)\n",
      "GPA: 3.85 / 4.5\n",
      "관련 과목: 머신러닝, 데이터마이닝, 통계학, 빅데이터처리, 딥러닝 이론과 실습\n",
      "[기술 스택]\n",
      "Programming: Python, SQL, R\n",
      "Frameworks/Libraries: Scikit-learn, TensorFlow, PyTorch, Pandas, NumPy\n",
      "Tools: Jupyter, Git, Docker, Tableau\n",
      "DBMS: MySQL, MongoDB, Hadoop(HDFS), Spark\n",
      "Cloud: Google Colab, AWS EC2 & S3 (기초 수준)\n",
      "[프로젝트 경험]\n",
      "1. 신문 기사 기반 감성 분석 모델 개발 (2023.03 ~ 2023.06)\n",
      "자연어처리(NLP) 기반 감성 분류 모델 개발\n",
      "KoNLPy와 Scikit-learn을 이용한 전처리 및 모델 학습\n",
      "정확도 86% 달성\n",
      "2. 머신러닝 기반 개인 맞춤형 영화 추천 시스템 (2023.09 ~ 2023.12)\n",
      "📄 이력서 (Resume)\n",
      "1\n",
      "Content-based Filtering 및 Collaborative Filtering 기법 적용\n",
      "Streamlit으로 웹 인터페이스 구현\n",
      "kaggle 데이터셋 기반, Precision@10: 0.73\n",
      "[자격증]\n",
      "ADsP (데이터분석 준전문가) – 2023.08\n",
      "SQLD (SQL 개발자) – 2024.01\n",
      "📄 이력서 (Resume)\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이력서 불러오기\n",
    "path = \"./data/빅데이터AI_이력서.pdf\"\n",
    "doc = fitz.open(path)\n",
    "resume_text=''\n",
    "for page in doc:\n",
    "    resume_text += page.get_text()\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_text :이력서 텍스트 입력 쿼리가 될 것\n",
    "\n",
    "# df : 채용공고 원본 데이터\n",
    "\n",
    "# document 구조\n",
    "# page_content  \n",
    "# 기업명, 공고명, [경력]\n",
    "# 직무, 지역 \n",
    "# 임베딩 되야할건 jd_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cdb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents 생성\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            f\"공고내용: {row['chunk']}, \"\n",
    "            f\"회사명: {row['company_nm']}, \"\n",
    "            f\"직무: {row['recruit_kewdcdnm']}, \"\n",
    "            f\"지역: {row['company_place']}, \"\n",
    "            f\"경력: {row['career']}, \"\n",
    "            f\"학력: {row['education']}\"\n",
    "        ),\n",
    "        metadata={\"rec_idx\": row['rec_idx'], \"company_nm\":}\n",
    "    )\n",
    "    for _, row in rec_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ed5104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295109/1344237561.py:8: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    }
   ],
   "source": [
    "# EC2 chroma data base에 적재\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 1. 임베딩 모델\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# 2. Chroma EC2 클라이언트 연결\n",
    "chroma_client = chromadb.HttpClient(\n",
    "    host=\"43.202.186.183\",\n",
    "    port=8000,\n",
    "    settings=Settings(allow_reset=True, anonymized_telemetry=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 문서 임베딩 + 적재 (cosine distance)\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=documents,  # rec_df에서 생성한 Document 리스트\n",
    "    embedding=embeddings,\n",
    "    client=chroma_client,\n",
    "    collection_name=\"job_position\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # cosine similarity 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적재 부분에서 너무 커서 임베딩 한계 토큰을 넘음 time 옵션 넣기\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 재시도 로직, 로깅 설정\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def embed_with_retry(docs):\n",
    "    try:\n",
    "        logging.debug(f\"Processing batch with {len(docs)} documents.\")\n",
    "        return Chroma.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            client=chroma_client,\n",
    "            collection_name=\"job_position\",\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in embedding: {e}\")\n",
    "        raise\n",
    "batch_size = 50  # 작은 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = documents[i:i+batch_size]\n",
    "    try:\n",
    "        embed_with_retry(batch)\n",
    "        print(f\"{i} ~ {i+batch_size} 적재 완료\")\n",
    "        time.sleep(2)  # 호출 간 간단한 지연 추가\n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생 - {i} ~ {i+batch_size}번째 문서 배치: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55368b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(\n",
    "    host=\"43.202.186.183\",\n",
    "    port=8000,\n",
    "    settings=Settings(allow_reset=True, anonymized_telemetry=False)\n",
    ")\n",
    "collection = chroma_client.get_collection(name=\"job_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.get()\n",
    "print(\"총 문서 수:\", len(results['documents']))\n",
    "print(\"예시 문서:\", results['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8516f66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295109/3214207519.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  chroma_db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] 공고내용: [보안AI사업본부] Python 백엔드 개발자 모집 채용공고 상세\n",
      "[보안AI사업본부] Python 백엔드 개발자 모집2008년 02월 15일에 설립된 응용 소프트웨어 개발 및 공급업업종의 의료 인공지능플랫폼,인공지능 임상의사결정 시스템 개발사업을 하는 코스닥,중소기업,외부감사법인,주식회사,병역특례 인증업체기업 입니다.모집부문 및 상세내용구   분상세내용공통 자격요건ㆍ학력 : 대졸 이상 (4년) / 컴퓨터 공학 또는 관련 전공자ㆍ경력 : 3년 이상 Python 백엔드 개발자 1명주요업무담당업무ㆍ담당업무ㆍPython 제품 안정화 개발 및 배포ㆍ영상 분석 AI와 제품 간 인터페이스 개발 담당자격요건ㆍPython 개발자 (프로젝트 포트폴리오 제출 필수)ㆍFastAPI와 같은 Python 웹 프레임워크 활용 경험우대사항ㆍPython을 통한 영상 AI 솔루션 개발 유 경험자ㆍPython 솔루션 개발 및 배포 유 경험자ㆍWindows OS에서 PyInstaller를 통한 배포 환경 경험 및 배포 관련 개선 경험자ㆍAI 모델 Docker 배포 경험자ㆍPython 외에 다양한 개발언어 활용 가능자보유자격 (필수는 아님 보유 시 우대)ㆍ정보처리기사, 운전면허 등 필수 제출 서류ㆍ면접 전 포트폴리오 제출 필수, 면접 시 포트폴리오 발표 진행 예정\n",
      "ㆍ기타 필수 사항\n",
      "우대사항근무조건ㆍ근무형태:정규직(수습기간)-3개월ㆍ근무일시:ㆍ근무지역:(08377) 서울 구로구 디지털로33길 48 대륭포스트타워7차 19층(구로동) - 서울 7호선 남구로 에서 800m 이내전형절차 서류전형 1차면접 2차면접 최종합격접수기간 및 방법ㆍ접수기간:2025년 3월 18일 (화) 21시~ 채용시ㆍ접수방법:사람인 입사지원ㆍ이력서양식:사람인 온라인 이력서ㆍ제출서류:포트폴리오 제출 필수 / 면접 시 포트폴리오 발표 진행 예정유의사항ㆍ학력, 성별, 연령을 보지않는 블라인드 채용입니다. ㆍ입사지원 서류에 허위사실이 발견될 경우, 채용확정 이후라도 채용이 취소될 수 있습니다.ㆍ모집분야별로 마감일이 상이할 수 있으니 유의하시길 바랍니다., 회사명: (주)딥노이드, 직무: ['백엔드/서버개발', 'Python'], 지역: 서울 구로구, 경력: 경력 3년↑ · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[2] 공고내용: 백엔드 엔지니어 (Backend Engineer(Senior, Python)) 채용공고 상세\n",
      "모집부문 및 상세내용공통 자격요건ㆍ학력 : 대졸 이상 (4년)Backend Engineer 0명담당업무ㆍ주요업무소프트웨어 엔지니어로서, Python을 사용하여 견고하고 확장 가능한 소프트웨어 솔루션을 설계하고 구현하는 데 중요한 역할을 맡게됩니다.전문가들로구성된팀과 협력하여 웹 애플리케이션을 개발 및 최적화하고, AWS 인프라를 자동화하며, 지속적배포 파이프라인을 구축 및 개선하고, 추적 및 모니터링 시스템을 확립하며, 시스템 보안을 보장하게 됩니다. 본 직무는 Python 전문 지식을 활용하면서 최첨단 AI 기술 개발에 기여할 수 있는 흥미로운 기회를 제공할 것 입니다.주요업무ㆍPython과 Django 프레임워크를 사용하여 소프트웨어 구성 요소 및 웹애플리케이션을 개발하고 최적화\n",
      "ㆍ고품질의 소프트웨어 개발 방식을 보장하기 위해 페어 프로그래밍에 참여\n",
      "ㆍ소프트웨어의 품질을 보장하기 위해 시스템의 모든 부분에 대한 자동화 된 테스트 작성\n",
      "ㆍ웹 애플리케이션을 위한 전체 시스템 아키텍처, 데이터베이스 스키마 및 API 설계\n",
      "ㆍ추천 시스템과 같은 애플리케이션의 비즈니스 로직 구현\n",
      "ㆍ성능, 신뢰성, 확장성을 보장하며 기존 소프트웨어 인프라 유지 및 개선\n",
      "ㆍ머신 러닝 팀과 협력하여 머신 러닝 모델을 위한 소프트웨어 솔루션 개발 및 구현\n",
      "ㆍ데이터 수집, 전처리, 특징 추출 및 시각화를 위한 소프트웨어 구성 요소를 설계, 개발, 최적화\n",
      "ㆍ확장성, 신뢰성 및 효율성 보장을 위한 AWS 인프라 자동화\n",
      "ㆍ배포 프로세스 간소화를 위해 지속적 배포 파이프라인 구축 및 개선\n",
      "ㆍ애플리케이션의 상태와 성능 보장을 위해 추적 및 모니터링 시스템 확립\n",
      "ㆍ시스템 보안 유지를 위해 팀이 모범 사례를 따르도록 보장 자격요건ㆍ컴퓨터 과학, 소프트웨어 공학 또는 관련 기술 분야에서 학사 학위 소지자\n",
      "ㆍPython 언어에 숙련된 프로그래밍 실력\n",
      "ㆍ애자일 소프트웨어 개발 방법론의 강력한 옹호자이자 실천자\n",
      "ㆍ정기적으로 페어 프로그래밍을 할 수 있는 능력과 열정 ㆍ시스템 보안 유지를 위해 팀이 모범 사례를 따르도록 보장 자격요건ㆍ컴퓨터 과학, 소프트웨어 공학 또는 관련 기술 분야에서 학사 학위 소지자\n",
      "ㆍPython 언어에 숙련된 프로그래밍 실력\n",
      "ㆍ애자일 소프트웨어 개발 방법론의 강력한 옹호자이자 실천자\n",
      "ㆍ정기적으로 페어 프로그래밍을 할 수 있는 능력과 열정\n",
      "ㆍ독립적 및 협업 환경 모두에서 효과적으로 일할 수 있는 능력\n",
      "ㆍ뛰어난 의사소통 및 대인 관계 능력\n",
      "ㆍ적극적인 문제 해결 및 분석 능력\n",
      "ㆍ세부사항에 집중하며, 강한 책임감을 가진 자기 동기부여 능력\n",
      "ㆍ빠르게 변화하는 역동적인 환경에서 일할 수 있는 능력\n",
      "ㆍ머신러닝 개념 및 알고리즘에 대한 탄탄한 이해\n",
      "ㆍAWS 및 인프라 자동화 경험\n",
      "ㆍ지속적 전달 프로세스와 DevOps 실천에 대한 충분한 지식\n",
      "ㆍ추적 및 모니터링 도구와 실천에 대한 지식 \n",
      "ㆍ소프트웨어 개발 및 운영에서 보안 모범 사례에 대한 깊은 이해우대조건ㆍ스타트업 근무 경험\n",
      "ㆍ새로운 기술에 관심이 있는 사람\n",
      "ㆍ급변하는 요구사항과 빠른 소통에 능한 사람\n",
      "ㆍAWS 또는 Google Cloud와 같은 클라우드 플랫폼 경험업무 환경ㆍ업무 관련 비용 상환\n",
      "ㆍ최고 수준의 기자재 제공\n",
      "ㆍ매월 운동 비용 제공\n",
      "ㆍ건강진단비 제공\n",
      "ㆍ컨퍼런스/학회 입장료 제공\n",
      "ㆍ무료 커피, 음료/스낵바 제공\n",
      "ㆍ휴일 보너스 및 생일선물\n",
      "ㆍ추천인 입사시 보너스ㆍ건강검진 제공\n",
      "ㆍ경조비 제공근무조건ㆍ근무형태:정규직 -수습기간 3개월ㆍ근무일시:채용 후 조정 / 주 5일(월~금) 오전 9시~오후 6시ㆍ근무지역:서울시 강서구 마곡중앙10로 91전형절차사전 심사양식 제출기술면접 컬쳐핏 면접임원면접최종합격접수기간 및 방법ㆍ접수기간:2025년 3월 18일 (화) 16시 ~ 상시ㆍ접수방법:사람인 입사지원ㆍ이력서양식:자유양식유의사항ㆍ학력, 성별, 연령을 보지않는 블라인드 채용입니다. ㆍ입사지원 서류에 허위사실이 발견될 경우, 채용확정 이후라도 채용이 취소될 수 있습니다.ㆍ모집분야별로 마감일이 상이할 수 있으니 유의하시길 바랍니다., 회사명: (주)마인드에이아이, 직무: ['딥러닝', '머신러닝', '빅데이터', '알고리즘', '챗봇'], 지역: 서울 강서구, 경력: 경력 4년↑ · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[3] 공고내용: Python 솔루션 개발자/빅데이터 분석가/Java 개발자 채용\n",
      "\n",
      "채용공고 상세\n",
      "We are hiring!\n",
      "바탕에비뉴(주)\n",
      "Python 솔루션 개발자\n",
      "/빅데이터 분석가\n",
      "/Java 개발자 채용\n",
      "바탕에비뉴(주)는 빅데이터 분석 및 IT 시스템 구축 전문 회사로\n",
      "2018년 4월 24일 법인 설립 하였습니다.\n",
      "데이터 분석을 통해서 대시보드 구현과 분석도구를 이용한 인공지능 알고리즘 통한\n",
      "모든 시스템을 자동화 분석 가능한 형태로 구축하고 있습니다.\n",
      "분석도구(EyeT)는 인공지능 분야, 텍스트 마이닝 분야, 데이터 정제/가공 분야,\n",
      "지리공간분석 분야에서 활용할 수 있는 다양한 기술이 탑재되어 있습니다.\n",
      "각 분야별 전문 인력과 많은 노하우와 경험을 바탕으로\n",
      "창의 있는 젊은 인재들의 참신한 아이디어를 점목하여 회사 운영을 하고 있으며,\n",
      "탄탄한 조직력과 좋은 사내 분위기를 갖춘 회사입니다.\n",
      "비젼있는 바탕에비뉴와 함께 멋진 미래를 펼쳐 나가실\n",
      "실력있고 유능한 인재를 찾고 있사오니 많은 지원 바랍니다.\n",
      "\t\t\t\t\t\n",
      " 모집부문\n",
      " 모집부문\n",
      " 주요업무\n",
      " 자격요건 및우대사항\n",
      " 인원\n",
      "Python 솔루션\n",
      "개발자\n",
      "[대리/과장급]\n",
      "ㆍPython 기반의 자사 데이터 분석\n",
      "   솔루션 엔진 개발 및 유지보수\n",
      "ㆍPython 기반의 윈도우즈 서비스\n",
      "   에이전트 개발 및 유지보수\n",
      "[자격요건]\n",
      "ㆍ학력 : 대졸 이상(4년)\n",
      "ㆍ경력 : Python 개발 경력 3년 이상\n",
      "ㆍPython의 데이터 분석 라이브러리(pandas,\n",
      "   scikit-learn, tensorflow 등) 활용 가능자\n",
      "ㆍ데이터 분석에 대한 지식 보유자 [우대사항]\n",
      "ㆍgeopandas를 사용한 공간 데이터 분석 경험자\n",
      "ㆍAnaconda3를 사용한 가상환경 활용 및 배포 경험자\n",
      "ㆍInno Setup Script를 활용한 인스톨러 \n",
      "    개발 및 배포 경험자\n",
      "ㆍWindows 기반의 소프트웨어 개발 및 배포 경험자\n",
      "ㆍ버전 관리 시스템 사용 경험자\n",
      "ㆍ데이터 분석 또는 AI 관련 프로젝트 경험자\n",
      "ㆍ컴퓨터 공학 계열 전공자\n",
      "ㆍ정보처리기사 또는 산업기사 보유자\n",
      "1명\n",
      "빅데이터 분석가\n",
      "ㆍ지자체/공공기관의 빅데이터 \n",
      "   분석 및 컨설팅 사업 수행\n",
      "   - 요구사항 기반 데이터 분석을 \n",
      "      통한 인사이트 도출 및 \n",
      "      의사결정 지원\n",
      "   - 분석결과 시각화 및 보고서 작성\n",
      "   - 빅데이터 활용 컨설팅 진행\n",
      "ㆍ제안서 작성\n",
      "   - 빅데이터 분석 및 활용 컨설팅\n",
      "      사업 관련 제안서 작성\n",
      "[자격요건]\n",
      "ㆍ학력 : 대졸 이상(4년)\n",
      "ㆍ경력 : 신입 및 경력 3년 이상\n",
      "ㆍ빅데이터 분석에 관한 기본적 이해도 보유자\n",
      "ㆍPython, SQL을 활용한 분석이 가능자\n",
      "ㆍMS Office(Excel, PowerPoint), 한글(hwp) \n",
      "   활용 가능자\n",
      "\n",
      "[우대사항]\n",
      "ㆍ관련학과 전공자\n",
      "ㆍ데이터 수집부터 전처리, EDA, 모델링, 결과 시각화 \n",
      "   및 인사이트 도출까지 분석 전 과정 경험자\n",
      "ㆍIT 관련 자격증 보유자\n",
      "ㆍ영상, NLP(자연어처리) 데이터 분석 가능자\n",
      "ㆍQGIS 활용 공간 데이터 분석 가능자\n",
      "1명\n",
      "Java 개발자\n",
      "ㆍ지자체/공공기관의 빅데이터 \n",
      "   플랫폼 개발 및 운영 사업 수행\n",
      "   - 빅데이터 분석결과 시각화\n",
      "ㆍJAVA 기반(Spring, Framework) \n",
      "    웹 개발\n",
      "[자격요건]\n",
      "ㆍ학력 : 대졸 이상(4년)\n",
      "ㆍ경력 : 경력 5년 이상 ㆍJava 기술 생태계(Java/Spring)에 대한 이해도와 \n",
      "   엔지니어링 역량 보유자\n",
      "ㆍHTML, css, x-javascript, JQuery에 대한 \n",
      "   기본 지식 보유자\n",
      "ㆍ웹 서비스를 위한 환경 구축 지식 보유자 \n",
      "   (WEB/WAS 등)\n",
      "ㆍDB 쿼리 작성 가능자\n",
      "\n",
      "[우대사항]\n",
      "ㆍ컴퓨터공학 관련 전공자\n",
      "ㆍ정보처리기사, 산업기사 자격증 보유자\n",
      "ㆍJava MVC Framework기반 웹 개발 경험자\n",
      "ㆍ신기술 습득을 위한 노력과 도전에 열정이 있는 자\n",
      "ㆍ협업 간, 커뮤니케이션에 어려움이 없는 자\n",
      "ㆍPPT 능숙자\n",
      "ㆍ인근 거주자\n",
      "1명\n",
      "근무조건\n",
      "ㆍ근무형태 : 정규직\n",
      "ㆍ근무요일/시간 : 주 5일(월~금) / 오전 9시 30분~오후 6시 30분\n",
      "ㆍ급여 : 면접 후 결정\n",
      "ㆍ회사주소 : 서울시 구로구 디지털로27가길 17 오닉스빌딩 7층\n",
      "복지 및 혜택\n",
      "지원금/보험\n",
      "각종 경조사 지원\n",
      " \n",
      "급여제도 \n",
      "퇴직연금\n",
      "선물 \n",
      "명절선물/귀향비, 창립일선물지급\n",
      " \n",
      "교육/생활\n",
      "창립일행사, 자기계발비 지원, \n",
      "간식 제공, 음료제공(차, 커피)\n",
      "근무 환경\n",
      "휴게실, 회의실, 카페테리아, 노트북, \n",
      "사원증, 사무용품 지급, \n",
      "최고 성능 컴퓨터\n",
      " \n",
      "조직문화 \n",
      "자유복장, 자유로운 연차사용\n",
      "출퇴근 \n",
      "주 40시간제 시행\n",
      " \n",
      "리프레시 \n",
      "근로자의 날 휴무\n",
      "전형절차\n",
      "제출서류 및 이력서\n",
      "ㆍ이력서, 입사지원서, 졸업증명서 및 자격증\n",
      "접수기간 및 방법\n",
      "ㆍ접수기간 : \n",
      "\n",
      "\t\t\t\t2025년 04월 06일까지\n",
      "\t\t\t\t\n",
      "\tㆍ접수방법 : 사람인 온라인 입사지원\n",
      "문의사항\n",
      "ㆍ담당자 : 조동환 (경영지원실)\n",
      "ㆍ연락처 : 02-6673-9493 \n",
      "유의사항\n",
      "ㆍ입사지원서 기재내용 및 제출서류가 허위일 경우 불합격 또는 입사취소 됩니다.\n",
      "홈페이지 바로가기, 회사명: 바탕에비뉴(주), 직무: ['기술지원', '데이터분석가', '데이터엔지니어', 'IT컨설팅', 'SE(시스템엔지니어)'], 지역: 서울 금천구 외, 경력: 경력 · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[4] 공고내용: [DX사업본부] 의료AI 제품개발/패키징 Python 개발자 채용공고 상세\n",
      "[DX사업본부] 의료AI 제품개발/패키징 Python 개발자2008년 02월 15일에 설립된 응용 소프트웨어 개발 및 공급업업종의 의료 인공지능플랫폼,인공지능 임상의사결정 시스템 개발사업을 하는 코스닥,중소기업,외부감사법인,주식회사,병역특례 인증업체기업 입니다.모집부문 및 상세내용공통 자격요건ㆍ학력 : 대졸 이상 (4년)Python 개발자의료영상사업부문 > DX사업본부 > 서비스개발팀 > 제품화 파트 2명담당업무ㆍ 의료AI 모델 제품화 패키징 및 배포ㆍ 의료AI 서비스 지원용 웹 애플리케이션 개발 유지보수 및 운영자격요건ㆍ 컴퓨터 공학 또는 관련 분야 학사 학위 이상 소지자ㆍPython에 대한 기본적인 이해와 개발 경험ㆍRESTful API 설계, 개발 및 연동 경험ㆍUbuntu 또는 기타 리눅스 환경에서의 개발 및 서버 관리 경험우대사항ㆍGit을 사용한 협업 및 버전 관리 수행 경험ㆍFastAPI와 같은 Python 웹 프레임워크 활용 경험ㆍPostgreSQL과 같은 데이터베이스 사용 경험ㆍDocker를 사용한 애플리케이션 컨테이너화 및 배포 경험ㆍ테스트 주도 개발 (TDD) 및 자동화된 테스트 작성 경험ㆍAWS, Azure, Ncloud 등 클라우드 서비스 사용 경험담당업무ㆍ지원자격ㆍ경력 : 신입/경력 4년 이하기타사항ㆍ 면접 전 포트폴리오 제출 필수 및 면접 시 포트폴리오 발표 진행ㆍ경력 : 경력 4년 ~ 12년\n",
      "ㆍ기타 필수 사항 ㆍ기타 필수 사항\n",
      "우대사항근무조건ㆍ근무형태:정규직(수습기간)-3개월ㆍ근무일시:유연근무제 09:00~18:00ㆍ근무지역:(08377) 서울 구로구 디지털로33길 48 대륭포스트타워7차 19층(구로동) - 서울 7호선 남구로 에서 800m 이내전형절차 서류전형 1차면접 최종합격접수기간 및 방법ㆍ접수기간:2025년 2월 7일 (금) 14시~ 2025년 4월 8일 (화) 24시ㆍ접수방법:사람인 입사지원ㆍ이력서양식:사람인 온라인 이력서ㆍ제출서류:포트폴리오 제출 필수(면접 시 포트폴리오 발표 진행)유의사항ㆍ학력, 성별, 연령을 보지않는 블라인드 채용입니다. ㆍ입사지원 서류에 허위사실이 발견될 경우, 채용확정 이후라도 채용이 취소될 수 있습니다.ㆍ모집분야별로 마감일이 상이할 수 있으니 유의하시길 바랍니다., 회사명: (주)딥노이드, 직무: ['백엔드/서버개발', '솔루션', 'Python'], 지역: 서울 구로구, 경력: 4 ~ 12년 · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[5] 공고내용: 백엔드 / 풀스택 개발자\n",
      "\n",
      "채용공고 상세\n",
      "백엔드 / 풀스택 개발자\n",
      "서비스 소개\n",
      "프리시젼바이오는 다양한 질병 표지자 검출 기술을 바탕으로 올바른 임상진단 솔루션을 제공하는 체외진단(IVD) 업체입니다.\n",
      "당사의 비전은 선진적인 진단 솔루션으로 임상적 견해를 도출하고 환자에 대한 헬스케어의 질을 향상시키는 것입니다.\n",
      "이 포지션의 AI 예상 면접 질문이 궁금하다면 점핏에서 확인해보세요!\n",
      "모집부문 / 상세내용\n",
      "사용 기술\n",
      " JavaScript PHP Spring Jira Docker Flutter Next.js GitHub\n",
      "주요업무\n",
      "• 체외진단기기 / 앱 연동 플랫폼 서버 설계/개발/관리\n",
      "• Java/Spring, Docker 등의 프레임워크를 활용한 개발\n",
      "• PHP, Next.js / Flutter 이해, App 연동 / 기기 연동 서버 개발\n",
      "• 클라우드, on-premise 서버 셋업 및 관리\n",
      "자격요건\n",
      "• 백엔드 설계 및 개발 경험\n",
      "• 프로젝트 전주기 경험\n",
      "• 서버 유지보수 경력\n",
      "우대사항\n",
      "• 인증, 보안 개발 경험\n",
      "• 문서화 및 S/W 버전 관리에 대한 높은 이해도\n",
      "• 의료/헬스케어 분야의 서비스 및 프로젝트 경험, 프로젝트 전주기 참여 경험(설계/개발/테스트/배포/고도화)\n",
      "마감일 및 근무지\n",
      "• 마감일 : ~2025-04-17• 근무지 - 서울 서초구 반포대로28길 50\n",
      "복지 및 혜택\n",
      "• 장기근속자 휴가 및 포상금 지급\n",
      "• 우수사원 및 모범사원 포상금 지급\n",
      "• 복지포인트 제공\n",
      "• 초과 근무 시 연장 근로수당 지급\n",
      "• 중식 제공\n",
      "• 생일 유급휴가 부여 및 상품권 지급\n",
      "• 음료 및 간식 지원\n",
      "• 경조금 및 휴가 지원\n",
      "• 법인 리조트 운영 \n",
      "• 외부교육비 지원 \n",
      "• 시차출퇴근제 운영 \n",
      "채용절차 및 기타 지원 유의사항\n",
      "\n",
      "• 서류전형 → 1차 인터뷰 → 2차 인터뷰 → 처우 협의 → 최종합격\n",
      "※절차는 변경될 수 있습니다.\n",
      "\n",
      "[지원 시 주의사항]\n",
      "• 3개월의 수습 기간이 있습니다.(수습 기간 동일 급여 보장) • 서류전형 → 1차 인터뷰 → 2차 인터뷰 → 처우 협의 → 최종합격\n",
      "※절차는 변경될 수 있습니다.\n",
      "\n",
      "[지원 시 주의사항]\n",
      "• 3개월의 수습 기간이 있습니다.(수습 기간 동일 급여 보장)\n",
      "\n",
      "[참고사항]\n",
      "• 서류 합격자에 한해 연락드립니다.\n",
      "• 본 채용은 수시 진행으로 우수 인재 채용 시 마감될 수 있습니다., 회사명: 프리시젼바이오(주), 직무: ['백엔드/서버개발', '앱개발', '웹개발', '퍼블리셔', '프론트엔드'], 지역: 서울 서초구 외, 경력: 8 ~ 15년 · 정규직, 학력: 대학(2,3년)↑\n"
     ]
    }
   ],
   "source": [
    "# chroma 유사도 검색 테스트 \n",
    "# Chroma 래퍼를 통해 기존 컬렉션 불러오기\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"job_position\",\n",
    "    embedding_function=embeddings,\n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "# similarity_search 수행\n",
    "query = \"python backend developer\"\n",
    "results = chroma_db.similarity_search(query, k=5)\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\n[{i+1}] {res.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742d26e",
   "metadata": {},
   "source": [
    "# 엘라스틱 서치 적재 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3633a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from langchain.vectorstores import ElasticsearchStore\n",
    "import uuid\n",
    "\n",
    "# Elasticsearch 연결 설정\n",
    "es_client = Elasticsearch (\"http://43.202.186.183:9200\", basic_auth=(\"elastic\", \"ElastiC7276\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2eb2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295109/1471931124.py:1: LangChainPendingDeprecationWarning: The class `ElasticsearchStore` will be deprecated in a future version. Use :class:`~Use class in langchain-elasticsearch package` instead.\n",
      "  elasticsearch_store = ElasticsearchStore(\n"
     ]
    }
   ],
   "source": [
    "elasticsearch_store = ElasticsearchStore(\n",
    "    es_connection=es_client,               # ← 여기서 네 es_client 사용\n",
    "    index_name=\"job_position\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00430f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'e350c3ef7c8e', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'LvpeIMa2RE21sK2gD6tyBA', 'version': {'number': '8.17.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '747663ddda3421467150de0e4301e8d4bc636b0c', 'build_date': '2025-02-05T22:10:57.067596412Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def embed_and_store(batch_docs):\n",
    "    ElasticsearchStore.from_documents(\n",
    "        documents=batch_docs,\n",
    "        embedding=embeddings,\n",
    "        index_name=\"job_position\",\n",
    "        es_connection=es_client,\n",
    "    )\n",
    "\n",
    "batch_size = 50  # 적절한 배치 사이즈 (20~50 추천)\n",
    "\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = documents[i:i+batch_size]\n",
    "    try:\n",
    "        embed_and_store(batch)\n",
    "        print(f\"{i} ~ {i+batch_size} 적재 완료\")\n",
    "        time.sleep(2)  # 너무 몰아서 호출하지 않도록\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {i} ~ {i+batch_size} 배치 적재 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df3570",
   "metadata": {},
   "source": [
    "# 여기서부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016f6b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_retriever = chroma_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "es_retriever = elasticsearch_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23df346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[chroma_retriever, es_retriever],\n",
    "    weights=[0.9, 0.1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078f0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = resume_text\n",
    "response = hybrid_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[hybrid_retriever]\")\n",
    "for doc in response:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c99c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 인재매칭 AI 어시스턴트입니다. 사용자 이력서에 기반하여 채용공고를 5개 추천해주세요.\n",
    "    \n",
    "    - 반드시 이력서에 기반할 것.\n",
    "    - 출력 시 채용공고의 양식을 사용할 것.\n",
    "    - 출력 시 지역은 상세하게 출력 할 것.\n",
    "    - 채용공고 추천 이유를 한줄로 설명할 것.         \n",
    "    - 같은 공고 번호가 중복될 경우 단 1개만 추천할 것.                  \n",
    "    - 채용공고 전체 내용을 기반하여 분석할 것. 제목만 보고 판단하지 말 것.\n",
    "    - page_content의 전체 텍스트를 기준으로 판단할 것.\n",
    "\n",
    "    #이력서: \n",
    "    {question} \n",
    "    #채용공고: \n",
    "    {context} \n",
    "\n",
    "    #출력형태\n",
    "    - 기업명, 공고명, [경력]\n",
    "    - 직무, 지역 \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=1)\n",
    "\n",
    "hybrid_chain = (\n",
    "    {\"context\": hybrid_retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "    #- 추천된 [채용공고]와 [이력서]를 참고하여 각 공고 별로 예상 면접 질문 5개를 만들 것.\n",
    "    #    - 면접 질문 유형은 아래와 같이 출력할 것.\n",
    "    #    - 1개 회사와 관련된 질문\n",
    "    #    - 2개 인적성 면접\n",
    "    #    - 2개 기술/역량 면접\n",
    "    #- 면접 질문은 웹 검색을 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79001414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- (주)유니와이즈솔루션즈, 연구소_AI 교육 정부 과제 연구원_경력\n",
      "  - 직무: ['데이터분석가', '데이터엔지니어', '데이터마이닝', '데이터시각화', '모델링'], 지역: 서울 강남구\n",
      "  - 추천 이유: AI 및 데이터 분석 관련 실무 경험과 Python 및 AI 프레임워크 지식이 요구되는 직무로, 사용자의 경력과 기술 스택과 잘 맞습니다.\n",
      "\n",
      "- (주)씨엘모빌리티, [강남] AI 연구소 개발 연구원 채용 (상시)\n",
      "  - 직무: ['딥러닝', '머신러닝', '연구원'], 지역: 서울 강남구 외\n",
      "  - 추천 이유: 딥러닝과 머신러닝 분야에 대한 깊은 이해와 경험이 요구되며, 사용자의 프로젝트 경험과 일치합니다.\n",
      "\n",
      "- (주)크랜베리, [경력] 파이썬 개발자 채용\n",
      "  - 직무: ['데이터분석가', '데이터엔지니어', '백엔드/서버개발', '앱개발', '웹개발'], 지역: 서울 금천구 외\n",
      "  - 추천 이유: Python과 AI 모델 운영 경험이 요구되며, 사용자의 기술과 경력을 효과적으로 활용할 수 있습니다.\n",
      "\n",
      "- (주)코난테크놀로지, 강화학습 개발자 채용\n",
      "  - 직무: ['딥러닝', '머신러닝', '모델링'], 지역: 서울 서초구\n",
      "  - 추천 이유: 파이썬과 강화학습 모델 개발 경험이 요구되며, 사용자의 학력과 프로젝트 경험이 이를 뒷받침합니다.\n",
      "\n",
      "- 한국과학기술연구원, 2025년 3월 연수직(연구인턴) 공개채용\n",
      "  - 직무: ['머신러닝', '모델링', '자율주행', '컴퓨터비전', 'AI(인공지능)'], 지역: 서울 성북구 외\n",
      "  - 추천 이유: 머신러닝과 AI 프로젝트 경험이 요구되며, 이는 사용자의 학력 및 프로젝트 경험과 잘 부합합니다.\n"
     ]
    }
   ],
   "source": [
    "response = hybrid_chain.invoke(resume_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a4a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 채용공고 추천 목록\n",
      "\n",
      "1. **기업명**: (주)크랜베리  \n",
      "   **공고명**: [경력] 파이썬 개발자 채용  \n",
      "   **직무**: 데이터분석가, 데이터엔지니어, 백엔드/서버개발, 앱개발, 웹개발  \n",
      "   **지역**: 서울 금천구 가산디지털1로 225 에이스 가산 포휴 316~318호  \n",
      "\n",
      "   **추천 이유**: 홍길동님의 파이썬 및 AI 모델 개발 경험이 회사의 요구사항에 부합합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)크랜베리의 AI 운영 시스템 개발에 어떻게 기여할 수 있을까요?\n",
      "   - **인적성 면접**:\n",
      "     1. 자신의 문제 해결 능력을 보여준 경험에 대해 이야기해 주세요.\n",
      "     2. 팀 내의 갈등을 해결한 경험이 있습니까? 어떻게 해결했나요?\n",
      "   - **기술/역량 면접**:\n",
      "     1. 파이썬을 사용하여 개발한 프로젝트가 있다면 설명해 주세요.\n",
      "     2. 대규모 데이터 핸들링 경험에 대해 설명해 주세요.\n",
      "\n",
      "2. **기업명**: (주)유니와이즈솔루션즈  \n",
      "   **공고명**: 연구소_AI 교육 정부 과제 연구원_경력  \n",
      "   **직무**: 데이터분석가, 데이터엔지니어, 데이터마이닝, 데이터시각화, 모델링  \n",
      "   **지역**: 서울 강남구 광평로 295, 2층  \n",
      "\n",
      "   **추천 이유**: 데이터 분석 및 AI 프레임워크에 대한 지식이 요구되는 직무로서, 홍길동님의 기술 스택과 일치합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)유니와이즈솔루션즈에서 AI 교육 연구를 진행할 때 중점을 두고 싶은 부분은 무엇인가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 데이터 분석에서 가장 중요한 요소는 무엇이라고 생각하나요?\n",
      "     2. 본인의 장단점에 대해 설명해 주세요.\n",
      "   - **기술/역량 면접**:\n",
      "     1. TensorFlow나 PyTorch를 활용한 프로젝트 경험이 있나요? 설명해 주세요.\n",
      "     2. AI 모델의 최적화 작업을 수행한 경험이 있다면 설명해 주세요.\n",
      "\n",
      "3. **기업명**: (주)씨엘모빌리티  \n",
      "   **공고명**: [강남] AI 연구소 개발 연구원 채용 (상시)  \n",
      "   **직무**: 딥러닝, 머신러닝, 연구원  \n",
      "   **지역**: 서울 강남구  \n",
      "\n",
      "   **추천 이유**: 딥러닝 및 머신러닝 관련 프로젝트 경험이 많은 홍길동님에게 적합한 직무입니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)씨엘모빌리티의 연구소에서 어떤 연구를 진행하고 싶으신가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 스트레스를 어떻게 관리하나요?\n",
      "     2. 커뮤니케이션 능력을 발휘한 경험을 설명해 주세요.\n",
      "   - **기술/역량 면접**:\n",
      "     1. 딥러닝 모델을 개발한 경험에 대해 설명해 주세요.\n",
      "     2. 머신러닝에서 모델의 성능을 평가하는 방법에 대해 설명해 주세요.\n",
      "\n",
      "4. **기업명**: 한국과학기술연구원  \n",
      "   **공고명**: 2025년 3월 연수직(연구인턴) 공개채용  \n",
      "   **직무**: 머신러닝, 모델링, 자율주행, 컴퓨터비전, AI(인공지능)  \n",
      "   **지역**: 서울 성북구  \n",
      "\n",
      "   **추천 이유**: 홍길동님의 학력과 프로젝트 경험이 인턴십 프로그램에 적합합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: 한국과학기술연구원의 인턴십에서 배우고 싶은 것은 무엇인가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 실패에서 배운 경험을 이야기해 주세요.\n",
      "     2. 여러 업무를 동시에 처리한 경험이 있나요? 어떻게 처리했나요?\n",
      "   - **기술/역량 면접**:\n",
      "     1. 머신러닝 프로젝트의 전반적인 과정에 대해 설명해 주세요.\n",
      "     2. 데이터 전처리의 중요성에 대해 설명해 주세요.\n",
      "\n",
      "5. **기업명**: (주)코난테크놀로지  \n",
      "   **공고명**: 강화학습 개발자 채용  \n",
      "   **직무**: 딥러닝, 머신러닝, 모델링  \n",
      "   **지역**: 서울 서초구 강남대로 327 대륭서초타워 9층  \n",
      "\n",
      "   **추천 이유**: 강화학습 및 파이썬 관련 경험이 회사의 요구사항과 부합합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)코난테크놀로지에서 강화학습을 활용하여 어떤 혁신을 이루고 싶으신가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 창의력을 발휘한 경험이 있다면 이야기해 주세요.\n",
      "     2. 본인의 가장 큰 실패는 무엇이었나요?\n",
      "   - **기술/역량 면접**:\n",
      "     1. 강화학습을 활용한 프로젝트 경험에 대해 설명해 주세요.\n",
      "     2. Docker와 같은 컨테이너 도구를 사용한 경험이 있나요? 설명해 주세요."
     ]
    }
   ],
   "source": [
    "for chunk in hybrid_chain.stream(resume_text):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adf871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4600b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
