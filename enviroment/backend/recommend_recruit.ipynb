{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b561eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b45c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "CHROMA_HOST = os.getenv(\"CHROMA_HOST\")\n",
    "CHROMA_PORT = os.getenv(\"CHROMA_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f0d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/job_opening.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e25cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_idx</th>\n",
       "      <th>recruit_url</th>\n",
       "      <th>jd_img_src</th>\n",
       "      <th>jd_text</th>\n",
       "      <th>jd_img_text</th>\n",
       "      <th>company_nm</th>\n",
       "      <th>company_info</th>\n",
       "      <th>recruit_title</th>\n",
       "      <th>recruit_kewdcdnm</th>\n",
       "      <th>company_place</th>\n",
       "      <th>career</th>\n",
       "      <th>education</th>\n",
       "      <th>jd_img_aws_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50245530</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n채용공고 상세\\n[코스닥 상장사] 경영기획본부 신입2007년 12월 11일에 설...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(주)하이로닉</td>\n",
       "      <td>코스닥</td>\n",
       "      <td>[코스닥 상장사] 경영기획 신입</td>\n",
       "      <td>['경영기획', '전략기획', '경영분석', '경영컨설팅', '사업관리']</td>\n",
       "      <td>경기 용인시 수지구</td>\n",
       "      <td>신입 · 정규직</td>\n",
       "      <td>대학교(4년)↑</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50275785</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n채용공고 상세\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>세일즈웍스코리아(유)</td>\n",
       "      <td>외국계</td>\n",
       "      <td>[외국계 본사 / 정규직 /복리후생有] 외국계 부문별 신입/경력직</td>\n",
       "      <td>['거래처관리', '고객관리', '매장관리', '매출관리', '데이터분석']</td>\n",
       "      <td>서울 강남구 외</td>\n",
       "      <td>경력무관 · 정규직 외</td>\n",
       "      <td>학력무관</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50275903</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n채용공고 상세\\nNHN  Dooray!올인원 협업 도구 두레이와 전자결재/게시판...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>엔에이치엔(주)</td>\n",
       "      <td>대기업</td>\n",
       "      <td>[NHN Dooray] ERP 서비스 기획</td>\n",
       "      <td>['ERP', '서비스기획']</td>\n",
       "      <td>경기 성남시 분당구</td>\n",
       "      <td>경력 4년↑ · 정규직</td>\n",
       "      <td>학력무관</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50254512</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>['https://www.saraminimage.co.kr/recruit/os_hk...</td>\n",
       "      <td>\\n채용공고 상세\\n모집부문 및 자격요건\\n 모집부문\\n 경력사항\\n 담당업무\\n자...</td>\n",
       "      <td>1. 기업명: ㈜글로벌스탠다드테크놀로지\\n2. 모집 분야: 액침냉각 담당\\n3. 모...</td>\n",
       "      <td>(주)글로벌스탠다드테크놀로지</td>\n",
       "      <td>코스닥</td>\n",
       "      <td>[GST] 액침냉각 담당 인재 채용</td>\n",
       "      <td>['SAP', '특허명세사', '특허관리', '특허분석', '특허컨설팅']</td>\n",
       "      <td>경기 화성시 외</td>\n",
       "      <td>경력 · 정규직</td>\n",
       "      <td>대학교(4년)↑</td>\n",
       "      <td>['https://skai07mock.s3.ap-northeast-2.amazona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49874934</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n채용공고 상세\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(주)에이치비투자그룹</td>\n",
       "      <td>-</td>\n",
       "      <td>(주)에이치비투자그룹 주식/코인 2025 상반기 영업(TM) 채용</td>\n",
       "      <td>['영업직', '전략기획', '투자전략', '투자자문사']</td>\n",
       "      <td>서울 영등포구</td>\n",
       "      <td>경력무관 · 정규직</td>\n",
       "      <td>학력무관</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>50185544</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>['https://www.saraminimage.co.kr/recruit/os_hk...</td>\n",
       "      <td>\\n채용공고 상세\\n 구분\\n 상세내용\\nBusiness\\nPO\\n(비교대출)\\n(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(주)핀다</td>\n",
       "      <td>-</td>\n",
       "      <td>Business PO (비교대출)</td>\n",
       "      <td>['사업기획', '서비스기획', 'PO(프로덕트오너)', '사업개발', '사업관리']</td>\n",
       "      <td>서울 강남구 외</td>\n",
       "      <td>4 ~ 7년 · 정규직</td>\n",
       "      <td>고졸↑</td>\n",
       "      <td>['https://skai07mock.s3.ap-northeast-2.amazona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13849</th>\n",
       "      <td>50170082</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>['https://www.saraminimage.co.kr/recruit/os_hk...</td>\n",
       "      <td>\\n채용공고 상세\\n\\t\\n\\t 오픈헬스케어(주) ㅣ 전략기획본부 투자팀 - 경력\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>오픈헬스케어(주)</td>\n",
       "      <td>-</td>\n",
       "      <td>전략기획본부 투자팀 - 경력</td>\n",
       "      <td>['투자전략', '투자검토', '투자분석', '투자심사', '투자자문']</td>\n",
       "      <td>서울 성동구 외</td>\n",
       "      <td>5 ~ 8년 · 정규직</td>\n",
       "      <td>대학교(4년)↑</td>\n",
       "      <td>['https://skai07mock.s3.ap-northeast-2.amazona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>50090229</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>['https://www.saraminimage.co.kr/recruit/os_hk...</td>\n",
       "      <td>\\n채용공고 상세\\n \\n (주)두나미스자산운용\\n \\n펀드마케팅 \\n경력3년이상(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(주)두나미스자산운용</td>\n",
       "      <td>-</td>\n",
       "      <td>펀드마케팅 경력 3년이상(대리~부장급)</td>\n",
       "      <td>['마케팅기획', '비즈니스마케팅', '통계/분석', '금융사무', '기업금융']</td>\n",
       "      <td>서울 강남구</td>\n",
       "      <td>경력 3년↑ · 정규직 외</td>\n",
       "      <td>대학교(4년)↑</td>\n",
       "      <td>['https://skai07mock.s3.ap-northeast-2.amazona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13851</th>\n",
       "      <td>50109575</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>['https://www.saraminimage.co.kr/recruit/os_hk...</td>\n",
       "      <td>\\n채용공고 상세\\n재무기획(FP&amp;A) 담당자 채용\\n# 모집부문 \\n모집부문\\n담...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(주)에코앤드림</td>\n",
       "      <td>코스닥</td>\n",
       "      <td>[코스닥] 재무기획(FP&amp;A) 담당자 채용 - 서울</td>\n",
       "      <td>['세무사', '회계사', '관리회계', '기업회계', '내부감사']</td>\n",
       "      <td>서울 금천구 외</td>\n",
       "      <td>경력 5년↑ · 정규직</td>\n",
       "      <td>대학교(4년)↑</td>\n",
       "      <td>['https://skai07mock.s3.ap-northeast-2.amazona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>50136151</td>\n",
       "      <td>https://www.saramin.co.kr/zf_user/jobs/relay/v...</td>\n",
       "      <td>['https://www.saraminimage.co.kr/recruit/os_hk...</td>\n",
       "      <td>\\n채용공고 상세\\n모집상세\\n 모집부문\\n 담당업무\\n 자격요건 및 우대사항\\n ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(사)월드쉐어</td>\n",
       "      <td>-</td>\n",
       "      <td>모금사업부/필리핀지부장/에티오피아지부장 채용</td>\n",
       "      <td>['관리회계', '급여(Payroll)', '법인결산', '자금관리', '자산관리']</td>\n",
       "      <td>서울 구로구 외</td>\n",
       "      <td>신입 · 경력 · 정규직 외</td>\n",
       "      <td>학력무관</td>\n",
       "      <td>['https://skai07mock.s3.ap-northeast-2.amazona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13853 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rec_idx                                        recruit_url  \\\n",
       "0      50245530  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "1      50275785  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "2      50275903  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "3      50254512  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "4      49874934  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "...         ...                                                ...   \n",
       "13848  50185544  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "13849  50170082  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "13850  50090229  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "13851  50109575  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "13852  50136151  https://www.saramin.co.kr/zf_user/jobs/relay/v...   \n",
       "\n",
       "                                              jd_img_src  \\\n",
       "0                                                     []   \n",
       "1                                                     []   \n",
       "2                                                     []   \n",
       "3      ['https://www.saraminimage.co.kr/recruit/os_hk...   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "13848  ['https://www.saraminimage.co.kr/recruit/os_hk...   \n",
       "13849  ['https://www.saraminimage.co.kr/recruit/os_hk...   \n",
       "13850  ['https://www.saraminimage.co.kr/recruit/os_hk...   \n",
       "13851  ['https://www.saraminimage.co.kr/recruit/os_hk...   \n",
       "13852  ['https://www.saraminimage.co.kr/recruit/os_hk...   \n",
       "\n",
       "                                                 jd_text  \\\n",
       "0      \\n채용공고 상세\\n[코스닥 상장사] 경영기획본부 신입2007년 12월 11일에 설...   \n",
       "1                                            \\n채용공고 상세\\n   \n",
       "2      \\n채용공고 상세\\nNHN  Dooray!올인원 협업 도구 두레이와 전자결재/게시판...   \n",
       "3      \\n채용공고 상세\\n모집부문 및 자격요건\\n 모집부문\\n 경력사항\\n 담당업무\\n자...   \n",
       "4                                            \\n채용공고 상세\\n   \n",
       "...                                                  ...   \n",
       "13848  \\n채용공고 상세\\n 구분\\n 상세내용\\nBusiness\\nPO\\n(비교대출)\\n(...   \n",
       "13849  \\n채용공고 상세\\n\\t\\n\\t 오픈헬스케어(주) ㅣ 전략기획본부 투자팀 - 경력\\...   \n",
       "13850  \\n채용공고 상세\\n \\n (주)두나미스자산운용\\n \\n펀드마케팅 \\n경력3년이상(...   \n",
       "13851  \\n채용공고 상세\\n재무기획(FP&A) 담당자 채용\\n# 모집부문 \\n모집부문\\n담...   \n",
       "13852  \\n채용공고 상세\\n모집상세\\n 모집부문\\n 담당업무\\n 자격요건 및 우대사항\\n ...   \n",
       "\n",
       "                                             jd_img_text       company_nm  \\\n",
       "0                                                    NaN          (주)하이로닉   \n",
       "1                                                    NaN      세일즈웍스코리아(유)   \n",
       "2                                                    NaN         엔에이치엔(주)   \n",
       "3      1. 기업명: ㈜글로벌스탠다드테크놀로지\\n2. 모집 분야: 액침냉각 담당\\n3. 모...  (주)글로벌스탠다드테크놀로지   \n",
       "4                                                    NaN      (주)에이치비투자그룹   \n",
       "...                                                  ...              ...   \n",
       "13848                                                NaN            (주)핀다   \n",
       "13849                                                NaN        오픈헬스케어(주)   \n",
       "13850                                                NaN      (주)두나미스자산운용   \n",
       "13851                                                NaN         (주)에코앤드림   \n",
       "13852                                                NaN          (사)월드쉐어   \n",
       "\n",
       "      company_info                         recruit_title  \\\n",
       "0              코스닥                     [코스닥 상장사] 경영기획 신입   \n",
       "1              외국계  [외국계 본사 / 정규직 /복리후생有] 외국계 부문별 신입/경력직   \n",
       "2              대기업               [NHN Dooray] ERP 서비스 기획   \n",
       "3              코스닥                   [GST] 액침냉각 담당 인재 채용   \n",
       "4                -  (주)에이치비투자그룹 주식/코인 2025 상반기 영업(TM) 채용   \n",
       "...            ...                                   ...   \n",
       "13848            -                    Business PO (비교대출)   \n",
       "13849            -                       전략기획본부 투자팀 - 경력   \n",
       "13850            -                 펀드마케팅 경력 3년이상(대리~부장급)   \n",
       "13851          코스닥          [코스닥] 재무기획(FP&A) 담당자 채용 - 서울   \n",
       "13852            -              모금사업부/필리핀지부장/에티오피아지부장 채용   \n",
       "\n",
       "                                      recruit_kewdcdnm company_place  \\\n",
       "0            ['경영기획', '전략기획', '경영분석', '경영컨설팅', '사업관리']    경기 용인시 수지구   \n",
       "1           ['거래처관리', '고객관리', '매장관리', '매출관리', '데이터분석']      서울 강남구 외   \n",
       "2                                     ['ERP', '서비스기획']    경기 성남시 분당구   \n",
       "3            ['SAP', '특허명세사', '특허관리', '특허분석', '특허컨설팅']      경기 화성시 외   \n",
       "4                     ['영업직', '전략기획', '투자전략', '투자자문사']       서울 영등포구   \n",
       "...                                                ...           ...   \n",
       "13848  ['사업기획', '서비스기획', 'PO(프로덕트오너)', '사업개발', '사업관리']      서울 강남구 외   \n",
       "13849         ['투자전략', '투자검토', '투자분석', '투자심사', '투자자문']      서울 성동구 외   \n",
       "13850    ['마케팅기획', '비즈니스마케팅', '통계/분석', '금융사무', '기업금융']        서울 강남구   \n",
       "13851           ['세무사', '회계사', '관리회계', '기업회계', '내부감사']      서울 금천구 외   \n",
       "13852  ['관리회계', '급여(Payroll)', '법인결산', '자금관리', '자산관리']      서울 구로구 외   \n",
       "\n",
       "                career education  \\\n",
       "0             신입 · 정규직  대학교(4년)↑   \n",
       "1         경력무관 · 정규직 외      학력무관   \n",
       "2         경력 4년↑ · 정규직      학력무관   \n",
       "3             경력 · 정규직  대학교(4년)↑   \n",
       "4           경력무관 · 정규직      학력무관   \n",
       "...                ...       ...   \n",
       "13848     4 ~ 7년 · 정규직       고졸↑   \n",
       "13849     5 ~ 8년 · 정규직  대학교(4년)↑   \n",
       "13850   경력 3년↑ · 정규직 외  대학교(4년)↑   \n",
       "13851     경력 5년↑ · 정규직  대학교(4년)↑   \n",
       "13852  신입 · 경력 · 정규직 외      학력무관   \n",
       "\n",
       "                                          jd_img_aws_src  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3      ['https://skai07mock.s3.ap-northeast-2.amazona...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "13848  ['https://skai07mock.s3.ap-northeast-2.amazona...  \n",
       "13849  ['https://skai07mock.s3.ap-northeast-2.amazona...  \n",
       "13850  ['https://skai07mock.s3.ap-northeast-2.amazona...  \n",
       "13851  ['https://skai07mock.s3.ap-northeast-2.amazona...  \n",
       "13852  ['https://skai07mock.s3.ap-northeast-2.amazona...  \n",
       "\n",
       "[13853 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d16931",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = pd.read_csv('../data_backup/rec_data.csv')\n",
    "rec_df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6816ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 코드가 분당 토큰 100만을 넘겼기에 사용\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 500\n",
    "batch_documents = [documents[i:i+batch_size] for i in range(0, len(documents), batch_size)]\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectordb = None\n",
    "\n",
    "for i, batch in enumerate(batch_documents):\n",
    "    print(f\"▶ Processing batch {i+1}/{len(batch_documents)}...\")\n",
    "    if i == 0:\n",
    "        vectordb = Chroma.from_documents(\n",
    "            documents=batch,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=\"./chroma_data\",\n",
    "            collection_name=\"chroma_test\"\n",
    "        )\n",
    "    else:\n",
    "        vectordb.add_documents(batch)\n",
    "\n",
    "    vectordb.persist()\n",
    "    sleep(65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c3311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 이력서\n",
      "(Resume)\n",
      "[기본 정보]\n",
      "이름: 홍길동\n",
      "연락처: 010-1234-5678\n",
      "이메일: honggildong.ai@gmail.com\n",
      "주소: 서울특별시 강남구 테헤란로 123\n",
      "[학력]\n",
      "고려대학교 컴퓨터학과 졸업 (2018.03 ~ 2024.02)\n",
      "GPA 3.85 / 4.5\n",
      "관련 과목: 머신러닝, 데이터마이닝, 통계학, 빅데이터처리, 딥러닝 이론과 실습\n",
      "[기술 스택]\n",
      "Programming: Python, SQL, R\n",
      "Frameworks/Libraries: Scikit-learn, TensorFlow, PyTorch, Pandas, NumPy\n",
      "Tools: Jupyter, Git, Docker, Tableau\n",
      "DBMS MySQL, MongoDB, Hadoop(HDFS), Spark\n",
      "Cloud: Google Colab, AWS EC2 & S3 기초 수준)\n",
      "[프로젝트 경험]\n",
      "1. 신문 기사 기반 감성 분석 모델 개발 (2023.03 ~ 2023.06)\n",
      "자연어처리(NLP) 기반 감성 분류 모델 개발\n",
      "KoNLPy와 Scikit-learn을 이용한 전처리 및 모델 학습\n",
      "정확도 86% 달성\n",
      "2. 머신러닝 기반 개인 맞춤형 영화 추천 시스템 (2023.09 ~ 2023.12)\n",
      "📄 이력서 (Resume) 1\n",
      "Content-based Filtering 및 Collaborative Filtering 기법 적용\n",
      "Streamlit으로 웹 인터페이스 구현\n",
      "kaggle 데이터셋 기반, Precision@10 0.73\n",
      "[자격증]\n",
      "ADsP 데이터분석 준전문가)  2023.08\n",
      "SQLD SQL 개발자)  2024.01\n",
      "📄 이력서 (Resume) 2\n",
      "✍ 자기소개서\n",
      "(Self-\n",
      "Introduction)\n",
      "[1. 성장 과정 및 성격의 장점]\n",
      "어릴 적부터 데이터를 기반으로 판단하는 것을 좋아했습니다. 수학 문제를 논리적으로 해결\n",
      "하며 쾌감을 느꼈고, 고등학교 때는 엑셀로 가계부를 분석해 가성비가 좋은 소비 습관을 도\n",
      "출해본 경험이 있습니다. 이러한 성향은 컴퓨터공학을 전공하면서 자연스럽게 데이터 분석\n",
      "분야에 대한 흥미로 이어졌습니다. 저는 꼼꼼하게 문제를 분석하고 해결하려는 태도를 갖고\n",
      "있으며, 팀원들과 협업 시에도 객관적인 데이터를 바탕으로 소통하려 노력합니다.\n",
      "[2. 학업 및 프로젝트 경험]\n",
      "대학교 재학 중 다양한 빅데이터 및 AI 관련 과목을 수강하며 기초를 탄탄히 다졌습니다. 특\n",
      "히 ‘데이터마이닝ʼ 수업에서는 실제 쇼핑몰 데이터를 기반으로 구매 패턴을 분석했고, 프로젝\n",
      "트로는 감성 분석, 추천 시스템 등 다양한 ML 기반 실습을 경험했습니다. 이 과정에서 모델\n",
      "성능 향상을 위해 하이퍼파라미터 튜닝, 데이터 전처리 방식 변경 등 다양한 시도를 하며 실\n",
      "무 감각을 익혔습니다.\n",
      "[3. 지원 동기 및 입사 후 포부]\n",
      "귀사의 빅데이터 기반 의사결정 시스템과 AI를 활용한 고객 맞춤 서비스에 깊은 인상을 받았\n",
      "습니다. 저는 데이터를 통해 인사이트를 발굴하고, 이를 바탕으로 실질적인 비즈니스 가치를\n",
      "만드는 데 기여하고 싶습니다. 입사 후에는 현업의 문제를 빠르게 이해하고, 분석-모델링-배\n",
      "포까지 이어지는 전 과정을 빠르게 습득하여, 팀에 꼭 필요한 분석가로 성장하고자 합니다.\n",
      "✍ 자기소개서 (Self-Introduction) 1\n",
      "🗂 포트폴리오 요약\n",
      "(Portfolio\n",
      "Summary)\n",
      "[1. 영화 추천 시스템 개발 (2023.09 ~ 2023.12)\n",
      "개요: 유저의 평점 데이터를 바탕으로 개인 맞춤형 영화 추천\n",
      "기술 스택: Python, Pandas, Scikit-learn, Streamlit\n",
      "주요 성과:\n",
      "다양한 필터링 기법 적용 후 Precision@10 0.73\n",
      "UI 배포 및 시연 영상 포함\n",
      "GitHub: github.com/honggildong/movie-recommend\n",
      "[2. 뉴스 기사 감성 분석 (2023.03 ~ 2023.06)\n",
      "개요: 텍스트 데이터에서 긍정/부정 감정 분류 모델 개발\n",
      "기술 스택: Python, KoNLPy, Scikit-learn, Word2Vec\n",
      "성과:\n",
      "감성 레이블링 후 정확도 86%\n",
      "보고서 및 모델 평가 결과 포함\n",
      "GitHub: github.com/honggildong/news-sentiment\n",
      "3. Tableau 기반 매출 분석 Dashboard 2023.05\n",
      "개요: 가상의 이커머스 데이터를 활용한 시각화 대시보드 제작\n",
      "기술: Tableau, Excel\n",
      "주요 항목: 월별 매출 추이, 카테고리별 매출 점유율, 지역별 성장률 시각화\n",
      "🗂 포트폴리오 요약 (Portfolio Summary) 1\n"
     ]
    }
   ],
   "source": [
    "# 이력서 불러오기 (pdfplumber)\n",
    "\n",
    "import pdfplumber\n",
    "\n",
    "# 이력서 파싱\n",
    "path = \"./data/빅데이터AI_이력서.pdf\"\n",
    "doc = pdfplumber.open(path).pages\n",
    "resume_text = \"\\n\".join([page.extract_text() for page in doc])\n",
    "print(resume_text)\n",
    "\n",
    "# 자소서 파싱\n",
    "path = \"./data/빅데이터AI_자기소개서.pdf\"\n",
    "doc = pdfplumber.open(path).pages\n",
    "cover_letter_text= \"\\n\".join([page.extract_text() for page in doc])\n",
    "print(cover_letter_text)\n",
    "\n",
    "# 포트폴리오 파싱\n",
    "path = \"./data/빅데이터AI_포트폴리오.pdf\"\n",
    "doc = pdfplumber.open(path).pages\n",
    "popol_text= \"\\n\".join([page.extract_text() for page in doc])\n",
    "print(popol_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d2f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 이력서 (Resume)\n",
      "[기본 정보]\n",
      "이름: 홍길동\n",
      "연락처: 010-1234-5678\n",
      "이메일: honggildong.ai@gmail.com\n",
      "주소: 서울특별시 강남구 테헤란로 123\n",
      "[학력]\n",
      "고려대학교 컴퓨터학과 졸업 (2018.03 ~ 2024.02)\n",
      "GPA: 3.85 / 4.5\n",
      "관련 과목: 머신러닝, 데이터마이닝, 통계학, 빅데이터처리, 딥러닝 이론과 실습\n",
      "[기술 스택]\n",
      "Programming: Python, SQL, R\n",
      "Frameworks/Libraries: Scikit-learn, TensorFlow, PyTorch, Pandas, NumPy\n",
      "Tools: Jupyter, Git, Docker, Tableau\n",
      "DBMS: MySQL, MongoDB, Hadoop(HDFS), Spark\n",
      "Cloud: Google Colab, AWS EC2 & S3 (기초 수준)\n",
      "[프로젝트 경험]\n",
      "1. 신문 기사 기반 감성 분석 모델 개발 (2023.03 ~ 2023.06)\n",
      "자연어처리(NLP) 기반 감성 분류 모델 개발\n",
      "KoNLPy와 Scikit-learn을 이용한 전처리 및 모델 학습\n",
      "정확도 86% 달성\n",
      "2. 머신러닝 기반 개인 맞춤형 영화 추천 시스템 (2023.09 ~ 2023.12)\n",
      "📄 이력서 (Resume)\n",
      "1\n",
      "Content-based Filtering 및 Collaborative Filtering 기법 적용\n",
      "Streamlit으로 웹 인터페이스 구현\n",
      "kaggle 데이터셋 기반, Precision@10: 0.73\n",
      "[자격증]\n",
      "ADsP (데이터분석 준전문가) – 2023.08\n",
      "SQLD (SQL 개발자) – 2024.01\n",
      "📄 이력서 (Resume)\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이력서 불러오기\n",
    "path = \"./data/빅데이터AI_이력서.pdf\"\n",
    "doc = fitz.open(path)\n",
    "resume_text=''\n",
    "for page in doc:\n",
    "    resume_text += page.get_text()\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_text :이력서 텍스트 입력 쿼리가 될 것\n",
    "\n",
    "# df : 채용공고 원본 데이터\n",
    "\n",
    "# document 구조\n",
    "# page_content  \n",
    "# 기업명, 공고명, [경력]\n",
    "# 직무, 지역 \n",
    "# 임베딩 되야할건 jd_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cdb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents 생성\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            f\"공고내용: {row['chunk']}, \"\n",
    "            f\"회사명: {row['company_nm']}, \"\n",
    "            f\"직무: {row['recruit_kewdcdnm']}, \"\n",
    "            f\"지역: {row['company_place']}, \"\n",
    "            f\"경력: {row['career']}, \"\n",
    "            f\"학력: {row['education']}\"\n",
    "        ),\n",
    "        metadata={\"rec_idx\": row['rec_idx'], \"company_nm\":}\n",
    "    )\n",
    "    for _, row in rec_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2ed5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC2 chroma data base에 적재\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "client = chromadb.HttpClient(host='43.202.186.183', port=8000, settings=Settings(allow_reset=True, anonymized_telemetry=False))\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "db = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"job_opening\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 문서 임베딩 + 적재 (cosine distance)\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=documents,  # rec_df에서 생성한 Document 리스트\n",
    "    embedding=embeddings,\n",
    "    client=chroma_client,\n",
    "    collection_name=\"job_position\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # cosine similarity 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적재 부분에서 너무 커서 임베딩 한계 토큰을 넘음 time 옵션 넣기\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 재시도 로직, 로깅 설정\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def embed_with_retry(docs):\n",
    "    try:\n",
    "        logging.debug(f\"Processing batch with {len(docs)} documents.\")\n",
    "        return Chroma.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            client=chroma_client,\n",
    "            collection_name=\"job_position\",\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in embedding: {e}\")\n",
    "        raise\n",
    "batch_size = 50  # 작은 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = documents[i:i+batch_size]\n",
    "    try:\n",
    "        embed_with_retry(batch)\n",
    "        print(f\"{i} ~ {i+batch_size} 적재 완료\")\n",
    "        time.sleep(2)  # 호출 간 간단한 지연 추가\n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생 - {i} ~ {i+batch_size}번째 문서 배치: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55368b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(\n",
    "    host=\"43.202.186.183\",\n",
    "    port=8000,\n",
    "    settings=Settings(allow_reset=True, anonymized_telemetry=False)\n",
    ")\n",
    "collection = chroma_client.get_collection(name=\"job_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.get()\n",
    "print(\"총 문서 수:\", len(results['documents']))\n",
    "print(\"예시 문서:\", results['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a9c0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma 래퍼를 통해 기존 컬렉션 불러오기\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"job_opening\",\n",
    "    embedding_function=embeddings,\n",
    "    client=chroma_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516f66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295109/3214207519.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  chroma_db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] 공고내용: [보안AI사업본부] Python 백엔드 개발자 모집 채용공고 상세\n",
      "[보안AI사업본부] Python 백엔드 개발자 모집2008년 02월 15일에 설립된 응용 소프트웨어 개발 및 공급업업종의 의료 인공지능플랫폼,인공지능 임상의사결정 시스템 개발사업을 하는 코스닥,중소기업,외부감사법인,주식회사,병역특례 인증업체기업 입니다.모집부문 및 상세내용구   분상세내용공통 자격요건ㆍ학력 : 대졸 이상 (4년) / 컴퓨터 공학 또는 관련 전공자ㆍ경력 : 3년 이상 Python 백엔드 개발자 1명주요업무담당업무ㆍ담당업무ㆍPython 제품 안정화 개발 및 배포ㆍ영상 분석 AI와 제품 간 인터페이스 개발 담당자격요건ㆍPython 개발자 (프로젝트 포트폴리오 제출 필수)ㆍFastAPI와 같은 Python 웹 프레임워크 활용 경험우대사항ㆍPython을 통한 영상 AI 솔루션 개발 유 경험자ㆍPython 솔루션 개발 및 배포 유 경험자ㆍWindows OS에서 PyInstaller를 통한 배포 환경 경험 및 배포 관련 개선 경험자ㆍAI 모델 Docker 배포 경험자ㆍPython 외에 다양한 개발언어 활용 가능자보유자격 (필수는 아님 보유 시 우대)ㆍ정보처리기사, 운전면허 등 필수 제출 서류ㆍ면접 전 포트폴리오 제출 필수, 면접 시 포트폴리오 발표 진행 예정\n",
      "ㆍ기타 필수 사항\n",
      "우대사항근무조건ㆍ근무형태:정규직(수습기간)-3개월ㆍ근무일시:ㆍ근무지역:(08377) 서울 구로구 디지털로33길 48 대륭포스트타워7차 19층(구로동) - 서울 7호선 남구로 에서 800m 이내전형절차 서류전형 1차면접 2차면접 최종합격접수기간 및 방법ㆍ접수기간:2025년 3월 18일 (화) 21시~ 채용시ㆍ접수방법:사람인 입사지원ㆍ이력서양식:사람인 온라인 이력서ㆍ제출서류:포트폴리오 제출 필수 / 면접 시 포트폴리오 발표 진행 예정유의사항ㆍ학력, 성별, 연령을 보지않는 블라인드 채용입니다. ㆍ입사지원 서류에 허위사실이 발견될 경우, 채용확정 이후라도 채용이 취소될 수 있습니다.ㆍ모집분야별로 마감일이 상이할 수 있으니 유의하시길 바랍니다., 회사명: (주)딥노이드, 직무: ['백엔드/서버개발', 'Python'], 지역: 서울 구로구, 경력: 경력 3년↑ · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[2] 공고내용: 백엔드 엔지니어 (Backend Engineer(Senior, Python)) 채용공고 상세\n",
      "모집부문 및 상세내용공통 자격요건ㆍ학력 : 대졸 이상 (4년)Backend Engineer 0명담당업무ㆍ주요업무소프트웨어 엔지니어로서, Python을 사용하여 견고하고 확장 가능한 소프트웨어 솔루션을 설계하고 구현하는 데 중요한 역할을 맡게됩니다.전문가들로구성된팀과 협력하여 웹 애플리케이션을 개발 및 최적화하고, AWS 인프라를 자동화하며, 지속적배포 파이프라인을 구축 및 개선하고, 추적 및 모니터링 시스템을 확립하며, 시스템 보안을 보장하게 됩니다. 본 직무는 Python 전문 지식을 활용하면서 최첨단 AI 기술 개발에 기여할 수 있는 흥미로운 기회를 제공할 것 입니다.주요업무ㆍPython과 Django 프레임워크를 사용하여 소프트웨어 구성 요소 및 웹애플리케이션을 개발하고 최적화\n",
      "ㆍ고품질의 소프트웨어 개발 방식을 보장하기 위해 페어 프로그래밍에 참여\n",
      "ㆍ소프트웨어의 품질을 보장하기 위해 시스템의 모든 부분에 대한 자동화 된 테스트 작성\n",
      "ㆍ웹 애플리케이션을 위한 전체 시스템 아키텍처, 데이터베이스 스키마 및 API 설계\n",
      "ㆍ추천 시스템과 같은 애플리케이션의 비즈니스 로직 구현\n",
      "ㆍ성능, 신뢰성, 확장성을 보장하며 기존 소프트웨어 인프라 유지 및 개선\n",
      "ㆍ머신 러닝 팀과 협력하여 머신 러닝 모델을 위한 소프트웨어 솔루션 개발 및 구현\n",
      "ㆍ데이터 수집, 전처리, 특징 추출 및 시각화를 위한 소프트웨어 구성 요소를 설계, 개발, 최적화\n",
      "ㆍ확장성, 신뢰성 및 효율성 보장을 위한 AWS 인프라 자동화\n",
      "ㆍ배포 프로세스 간소화를 위해 지속적 배포 파이프라인 구축 및 개선\n",
      "ㆍ애플리케이션의 상태와 성능 보장을 위해 추적 및 모니터링 시스템 확립\n",
      "ㆍ시스템 보안 유지를 위해 팀이 모범 사례를 따르도록 보장 자격요건ㆍ컴퓨터 과학, 소프트웨어 공학 또는 관련 기술 분야에서 학사 학위 소지자\n",
      "ㆍPython 언어에 숙련된 프로그래밍 실력\n",
      "ㆍ애자일 소프트웨어 개발 방법론의 강력한 옹호자이자 실천자\n",
      "ㆍ정기적으로 페어 프로그래밍을 할 수 있는 능력과 열정 ㆍ시스템 보안 유지를 위해 팀이 모범 사례를 따르도록 보장 자격요건ㆍ컴퓨터 과학, 소프트웨어 공학 또는 관련 기술 분야에서 학사 학위 소지자\n",
      "ㆍPython 언어에 숙련된 프로그래밍 실력\n",
      "ㆍ애자일 소프트웨어 개발 방법론의 강력한 옹호자이자 실천자\n",
      "ㆍ정기적으로 페어 프로그래밍을 할 수 있는 능력과 열정\n",
      "ㆍ독립적 및 협업 환경 모두에서 효과적으로 일할 수 있는 능력\n",
      "ㆍ뛰어난 의사소통 및 대인 관계 능력\n",
      "ㆍ적극적인 문제 해결 및 분석 능력\n",
      "ㆍ세부사항에 집중하며, 강한 책임감을 가진 자기 동기부여 능력\n",
      "ㆍ빠르게 변화하는 역동적인 환경에서 일할 수 있는 능력\n",
      "ㆍ머신러닝 개념 및 알고리즘에 대한 탄탄한 이해\n",
      "ㆍAWS 및 인프라 자동화 경험\n",
      "ㆍ지속적 전달 프로세스와 DevOps 실천에 대한 충분한 지식\n",
      "ㆍ추적 및 모니터링 도구와 실천에 대한 지식 \n",
      "ㆍ소프트웨어 개발 및 운영에서 보안 모범 사례에 대한 깊은 이해우대조건ㆍ스타트업 근무 경험\n",
      "ㆍ새로운 기술에 관심이 있는 사람\n",
      "ㆍ급변하는 요구사항과 빠른 소통에 능한 사람\n",
      "ㆍAWS 또는 Google Cloud와 같은 클라우드 플랫폼 경험업무 환경ㆍ업무 관련 비용 상환\n",
      "ㆍ최고 수준의 기자재 제공\n",
      "ㆍ매월 운동 비용 제공\n",
      "ㆍ건강진단비 제공\n",
      "ㆍ컨퍼런스/학회 입장료 제공\n",
      "ㆍ무료 커피, 음료/스낵바 제공\n",
      "ㆍ휴일 보너스 및 생일선물\n",
      "ㆍ추천인 입사시 보너스ㆍ건강검진 제공\n",
      "ㆍ경조비 제공근무조건ㆍ근무형태:정규직 -수습기간 3개월ㆍ근무일시:채용 후 조정 / 주 5일(월~금) 오전 9시~오후 6시ㆍ근무지역:서울시 강서구 마곡중앙10로 91전형절차사전 심사양식 제출기술면접 컬쳐핏 면접임원면접최종합격접수기간 및 방법ㆍ접수기간:2025년 3월 18일 (화) 16시 ~ 상시ㆍ접수방법:사람인 입사지원ㆍ이력서양식:자유양식유의사항ㆍ학력, 성별, 연령을 보지않는 블라인드 채용입니다. ㆍ입사지원 서류에 허위사실이 발견될 경우, 채용확정 이후라도 채용이 취소될 수 있습니다.ㆍ모집분야별로 마감일이 상이할 수 있으니 유의하시길 바랍니다., 회사명: (주)마인드에이아이, 직무: ['딥러닝', '머신러닝', '빅데이터', '알고리즘', '챗봇'], 지역: 서울 강서구, 경력: 경력 4년↑ · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[3] 공고내용: Python 솔루션 개발자/빅데이터 분석가/Java 개발자 채용\n",
      "\n",
      "채용공고 상세\n",
      "We are hiring!\n",
      "바탕에비뉴(주)\n",
      "Python 솔루션 개발자\n",
      "/빅데이터 분석가\n",
      "/Java 개발자 채용\n",
      "바탕에비뉴(주)는 빅데이터 분석 및 IT 시스템 구축 전문 회사로\n",
      "2018년 4월 24일 법인 설립 하였습니다.\n",
      "데이터 분석을 통해서 대시보드 구현과 분석도구를 이용한 인공지능 알고리즘 통한\n",
      "모든 시스템을 자동화 분석 가능한 형태로 구축하고 있습니다.\n",
      "분석도구(EyeT)는 인공지능 분야, 텍스트 마이닝 분야, 데이터 정제/가공 분야,\n",
      "지리공간분석 분야에서 활용할 수 있는 다양한 기술이 탑재되어 있습니다.\n",
      "각 분야별 전문 인력과 많은 노하우와 경험을 바탕으로\n",
      "창의 있는 젊은 인재들의 참신한 아이디어를 점목하여 회사 운영을 하고 있으며,\n",
      "탄탄한 조직력과 좋은 사내 분위기를 갖춘 회사입니다.\n",
      "비젼있는 바탕에비뉴와 함께 멋진 미래를 펼쳐 나가실\n",
      "실력있고 유능한 인재를 찾고 있사오니 많은 지원 바랍니다.\n",
      "\t\t\t\t\t\n",
      " 모집부문\n",
      " 모집부문\n",
      " 주요업무\n",
      " 자격요건 및우대사항\n",
      " 인원\n",
      "Python 솔루션\n",
      "개발자\n",
      "[대리/과장급]\n",
      "ㆍPython 기반의 자사 데이터 분석\n",
      "   솔루션 엔진 개발 및 유지보수\n",
      "ㆍPython 기반의 윈도우즈 서비스\n",
      "   에이전트 개발 및 유지보수\n",
      "[자격요건]\n",
      "ㆍ학력 : 대졸 이상(4년)\n",
      "ㆍ경력 : Python 개발 경력 3년 이상\n",
      "ㆍPython의 데이터 분석 라이브러리(pandas,\n",
      "   scikit-learn, tensorflow 등) 활용 가능자\n",
      "ㆍ데이터 분석에 대한 지식 보유자 [우대사항]\n",
      "ㆍgeopandas를 사용한 공간 데이터 분석 경험자\n",
      "ㆍAnaconda3를 사용한 가상환경 활용 및 배포 경험자\n",
      "ㆍInno Setup Script를 활용한 인스톨러 \n",
      "    개발 및 배포 경험자\n",
      "ㆍWindows 기반의 소프트웨어 개발 및 배포 경험자\n",
      "ㆍ버전 관리 시스템 사용 경험자\n",
      "ㆍ데이터 분석 또는 AI 관련 프로젝트 경험자\n",
      "ㆍ컴퓨터 공학 계열 전공자\n",
      "ㆍ정보처리기사 또는 산업기사 보유자\n",
      "1명\n",
      "빅데이터 분석가\n",
      "ㆍ지자체/공공기관의 빅데이터 \n",
      "   분석 및 컨설팅 사업 수행\n",
      "   - 요구사항 기반 데이터 분석을 \n",
      "      통한 인사이트 도출 및 \n",
      "      의사결정 지원\n",
      "   - 분석결과 시각화 및 보고서 작성\n",
      "   - 빅데이터 활용 컨설팅 진행\n",
      "ㆍ제안서 작성\n",
      "   - 빅데이터 분석 및 활용 컨설팅\n",
      "      사업 관련 제안서 작성\n",
      "[자격요건]\n",
      "ㆍ학력 : 대졸 이상(4년)\n",
      "ㆍ경력 : 신입 및 경력 3년 이상\n",
      "ㆍ빅데이터 분석에 관한 기본적 이해도 보유자\n",
      "ㆍPython, SQL을 활용한 분석이 가능자\n",
      "ㆍMS Office(Excel, PowerPoint), 한글(hwp) \n",
      "   활용 가능자\n",
      "\n",
      "[우대사항]\n",
      "ㆍ관련학과 전공자\n",
      "ㆍ데이터 수집부터 전처리, EDA, 모델링, 결과 시각화 \n",
      "   및 인사이트 도출까지 분석 전 과정 경험자\n",
      "ㆍIT 관련 자격증 보유자\n",
      "ㆍ영상, NLP(자연어처리) 데이터 분석 가능자\n",
      "ㆍQGIS 활용 공간 데이터 분석 가능자\n",
      "1명\n",
      "Java 개발자\n",
      "ㆍ지자체/공공기관의 빅데이터 \n",
      "   플랫폼 개발 및 운영 사업 수행\n",
      "   - 빅데이터 분석결과 시각화\n",
      "ㆍJAVA 기반(Spring, Framework) \n",
      "    웹 개발\n",
      "[자격요건]\n",
      "ㆍ학력 : 대졸 이상(4년)\n",
      "ㆍ경력 : 경력 5년 이상 ㆍJava 기술 생태계(Java/Spring)에 대한 이해도와 \n",
      "   엔지니어링 역량 보유자\n",
      "ㆍHTML, css, x-javascript, JQuery에 대한 \n",
      "   기본 지식 보유자\n",
      "ㆍ웹 서비스를 위한 환경 구축 지식 보유자 \n",
      "   (WEB/WAS 등)\n",
      "ㆍDB 쿼리 작성 가능자\n",
      "\n",
      "[우대사항]\n",
      "ㆍ컴퓨터공학 관련 전공자\n",
      "ㆍ정보처리기사, 산업기사 자격증 보유자\n",
      "ㆍJava MVC Framework기반 웹 개발 경험자\n",
      "ㆍ신기술 습득을 위한 노력과 도전에 열정이 있는 자\n",
      "ㆍ협업 간, 커뮤니케이션에 어려움이 없는 자\n",
      "ㆍPPT 능숙자\n",
      "ㆍ인근 거주자\n",
      "1명\n",
      "근무조건\n",
      "ㆍ근무형태 : 정규직\n",
      "ㆍ근무요일/시간 : 주 5일(월~금) / 오전 9시 30분~오후 6시 30분\n",
      "ㆍ급여 : 면접 후 결정\n",
      "ㆍ회사주소 : 서울시 구로구 디지털로27가길 17 오닉스빌딩 7층\n",
      "복지 및 혜택\n",
      "지원금/보험\n",
      "각종 경조사 지원\n",
      " \n",
      "급여제도 \n",
      "퇴직연금\n",
      "선물 \n",
      "명절선물/귀향비, 창립일선물지급\n",
      " \n",
      "교육/생활\n",
      "창립일행사, 자기계발비 지원, \n",
      "간식 제공, 음료제공(차, 커피)\n",
      "근무 환경\n",
      "휴게실, 회의실, 카페테리아, 노트북, \n",
      "사원증, 사무용품 지급, \n",
      "최고 성능 컴퓨터\n",
      " \n",
      "조직문화 \n",
      "자유복장, 자유로운 연차사용\n",
      "출퇴근 \n",
      "주 40시간제 시행\n",
      " \n",
      "리프레시 \n",
      "근로자의 날 휴무\n",
      "전형절차\n",
      "제출서류 및 이력서\n",
      "ㆍ이력서, 입사지원서, 졸업증명서 및 자격증\n",
      "접수기간 및 방법\n",
      "ㆍ접수기간 : \n",
      "\n",
      "\t\t\t\t2025년 04월 06일까지\n",
      "\t\t\t\t\n",
      "\tㆍ접수방법 : 사람인 온라인 입사지원\n",
      "문의사항\n",
      "ㆍ담당자 : 조동환 (경영지원실)\n",
      "ㆍ연락처 : 02-6673-9493 \n",
      "유의사항\n",
      "ㆍ입사지원서 기재내용 및 제출서류가 허위일 경우 불합격 또는 입사취소 됩니다.\n",
      "홈페이지 바로가기, 회사명: 바탕에비뉴(주), 직무: ['기술지원', '데이터분석가', '데이터엔지니어', 'IT컨설팅', 'SE(시스템엔지니어)'], 지역: 서울 금천구 외, 경력: 경력 · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[4] 공고내용: [DX사업본부] 의료AI 제품개발/패키징 Python 개발자 채용공고 상세\n",
      "[DX사업본부] 의료AI 제품개발/패키징 Python 개발자2008년 02월 15일에 설립된 응용 소프트웨어 개발 및 공급업업종의 의료 인공지능플랫폼,인공지능 임상의사결정 시스템 개발사업을 하는 코스닥,중소기업,외부감사법인,주식회사,병역특례 인증업체기업 입니다.모집부문 및 상세내용공통 자격요건ㆍ학력 : 대졸 이상 (4년)Python 개발자의료영상사업부문 > DX사업본부 > 서비스개발팀 > 제품화 파트 2명담당업무ㆍ 의료AI 모델 제품화 패키징 및 배포ㆍ 의료AI 서비스 지원용 웹 애플리케이션 개발 유지보수 및 운영자격요건ㆍ 컴퓨터 공학 또는 관련 분야 학사 학위 이상 소지자ㆍPython에 대한 기본적인 이해와 개발 경험ㆍRESTful API 설계, 개발 및 연동 경험ㆍUbuntu 또는 기타 리눅스 환경에서의 개발 및 서버 관리 경험우대사항ㆍGit을 사용한 협업 및 버전 관리 수행 경험ㆍFastAPI와 같은 Python 웹 프레임워크 활용 경험ㆍPostgreSQL과 같은 데이터베이스 사용 경험ㆍDocker를 사용한 애플리케이션 컨테이너화 및 배포 경험ㆍ테스트 주도 개발 (TDD) 및 자동화된 테스트 작성 경험ㆍAWS, Azure, Ncloud 등 클라우드 서비스 사용 경험담당업무ㆍ지원자격ㆍ경력 : 신입/경력 4년 이하기타사항ㆍ 면접 전 포트폴리오 제출 필수 및 면접 시 포트폴리오 발표 진행ㆍ경력 : 경력 4년 ~ 12년\n",
      "ㆍ기타 필수 사항 ㆍ기타 필수 사항\n",
      "우대사항근무조건ㆍ근무형태:정규직(수습기간)-3개월ㆍ근무일시:유연근무제 09:00~18:00ㆍ근무지역:(08377) 서울 구로구 디지털로33길 48 대륭포스트타워7차 19층(구로동) - 서울 7호선 남구로 에서 800m 이내전형절차 서류전형 1차면접 최종합격접수기간 및 방법ㆍ접수기간:2025년 2월 7일 (금) 14시~ 2025년 4월 8일 (화) 24시ㆍ접수방법:사람인 입사지원ㆍ이력서양식:사람인 온라인 이력서ㆍ제출서류:포트폴리오 제출 필수(면접 시 포트폴리오 발표 진행)유의사항ㆍ학력, 성별, 연령을 보지않는 블라인드 채용입니다. ㆍ입사지원 서류에 허위사실이 발견될 경우, 채용확정 이후라도 채용이 취소될 수 있습니다.ㆍ모집분야별로 마감일이 상이할 수 있으니 유의하시길 바랍니다., 회사명: (주)딥노이드, 직무: ['백엔드/서버개발', '솔루션', 'Python'], 지역: 서울 구로구, 경력: 4 ~ 12년 · 정규직, 학력: 대학교(4년)↑\n",
      "\n",
      "[5] 공고내용: 백엔드 / 풀스택 개발자\n",
      "\n",
      "채용공고 상세\n",
      "백엔드 / 풀스택 개발자\n",
      "서비스 소개\n",
      "프리시젼바이오는 다양한 질병 표지자 검출 기술을 바탕으로 올바른 임상진단 솔루션을 제공하는 체외진단(IVD) 업체입니다.\n",
      "당사의 비전은 선진적인 진단 솔루션으로 임상적 견해를 도출하고 환자에 대한 헬스케어의 질을 향상시키는 것입니다.\n",
      "이 포지션의 AI 예상 면접 질문이 궁금하다면 점핏에서 확인해보세요!\n",
      "모집부문 / 상세내용\n",
      "사용 기술\n",
      " JavaScript PHP Spring Jira Docker Flutter Next.js GitHub\n",
      "주요업무\n",
      "• 체외진단기기 / 앱 연동 플랫폼 서버 설계/개발/관리\n",
      "• Java/Spring, Docker 등의 프레임워크를 활용한 개발\n",
      "• PHP, Next.js / Flutter 이해, App 연동 / 기기 연동 서버 개발\n",
      "• 클라우드, on-premise 서버 셋업 및 관리\n",
      "자격요건\n",
      "• 백엔드 설계 및 개발 경험\n",
      "• 프로젝트 전주기 경험\n",
      "• 서버 유지보수 경력\n",
      "우대사항\n",
      "• 인증, 보안 개발 경험\n",
      "• 문서화 및 S/W 버전 관리에 대한 높은 이해도\n",
      "• 의료/헬스케어 분야의 서비스 및 프로젝트 경험, 프로젝트 전주기 참여 경험(설계/개발/테스트/배포/고도화)\n",
      "마감일 및 근무지\n",
      "• 마감일 : ~2025-04-17• 근무지 - 서울 서초구 반포대로28길 50\n",
      "복지 및 혜택\n",
      "• 장기근속자 휴가 및 포상금 지급\n",
      "• 우수사원 및 모범사원 포상금 지급\n",
      "• 복지포인트 제공\n",
      "• 초과 근무 시 연장 근로수당 지급\n",
      "• 중식 제공\n",
      "• 생일 유급휴가 부여 및 상품권 지급\n",
      "• 음료 및 간식 지원\n",
      "• 경조금 및 휴가 지원\n",
      "• 법인 리조트 운영 \n",
      "• 외부교육비 지원 \n",
      "• 시차출퇴근제 운영 \n",
      "채용절차 및 기타 지원 유의사항\n",
      "\n",
      "• 서류전형 → 1차 인터뷰 → 2차 인터뷰 → 처우 협의 → 최종합격\n",
      "※절차는 변경될 수 있습니다.\n",
      "\n",
      "[지원 시 주의사항]\n",
      "• 3개월의 수습 기간이 있습니다.(수습 기간 동일 급여 보장) • 서류전형 → 1차 인터뷰 → 2차 인터뷰 → 처우 협의 → 최종합격\n",
      "※절차는 변경될 수 있습니다.\n",
      "\n",
      "[지원 시 주의사항]\n",
      "• 3개월의 수습 기간이 있습니다.(수습 기간 동일 급여 보장)\n",
      "\n",
      "[참고사항]\n",
      "• 서류 합격자에 한해 연락드립니다.\n",
      "• 본 채용은 수시 진행으로 우수 인재 채용 시 마감될 수 있습니다., 회사명: 프리시젼바이오(주), 직무: ['백엔드/서버개발', '앱개발', '웹개발', '퍼블리셔', '프론트엔드'], 지역: 서울 서초구 외, 경력: 8 ~ 15년 · 정규직, 학력: 대학(2,3년)↑\n"
     ]
    }
   ],
   "source": [
    "# chroma 유사도 검색 테스트 \n",
    "\n",
    "# similarity_search 수행\n",
    "query = \"python backend developer\"\n",
    "results = chroma_db.similarity_search(query, k=5)\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\n[{i+1}] {res.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742d26e",
   "metadata": {},
   "source": [
    "# 엘라스틱 서치 적재 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3633a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from langchain.vectorstores import ElasticsearchStore\n",
    "import uuid\n",
    "\n",
    "# Elasticsearch 연결 설정\n",
    "es_client = Elasticsearch (\"http://43.202.186.183:9200\", basic_auth=(\"elastic\", \"ElastiC7276\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2eb2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticsearch_store = ElasticsearchStore(\n",
    "    es_connection=es_client,               # ← 여기서 네 es_client 사용\n",
    "    index_name=\"job_position\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00430f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'media_type_header_exception', 'Invalid media-type value on headers [Content-Type, Accept]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mes_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:415\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:2991\u001b[0m, in \u001b[0;36mElasticsearch.info\u001b[0;34m(self, error_trace, filter_path, human, pretty)\u001b[0m\n\u001b[1;32m   2989\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretty\n\u001b[1;32m   2990\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 2991\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2992\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2998\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:351\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    349\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    352\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'media_type_header_exception', 'Invalid media-type value on headers [Content-Type, Accept]')"
     ]
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def embed_and_store(batch_docs):\n",
    "    ElasticsearchStore.from_documents(\n",
    "        documents=batch_docs,\n",
    "        embedding=embeddings,\n",
    "        index_name=\"job_position\",\n",
    "        es_connection=es_client,\n",
    "    )\n",
    "\n",
    "batch_size = 50  # 적절한 배치 사이즈 (20~50 추천)\n",
    "\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = documents[i:i+batch_size]\n",
    "    try:\n",
    "        embed_and_store(batch)\n",
    "        print(f\"{i} ~ {i+batch_size} 적재 완료\")\n",
    "        time.sleep(2)  # 너무 몰아서 호출하지 않도록\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {i} ~ {i+batch_size} 배치 적재 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df3570",
   "metadata": {},
   "source": [
    "# 여기서부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "016f6b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_retriever = chroma_db.as_retriever(search_kwargs={\"k\": 20})\n",
    "es_retriever = elasticsearch_store.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23df346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[chroma_retriever, es_retriever],\n",
    "    weights=[0.7, 0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f0449",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Collection expecting embedding with dimension of 384, got 1536",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# query = resume_text\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m[이력서]\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mresume_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mpopol_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/retrievers/ensemble.py:118\u001b[0m, in \u001b[0;36mEnsembleRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    117\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    121\u001b[0m         result,\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    123\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/retrievers/ensemble.py:115\u001b[0m, in \u001b[0;36mEnsembleRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_retriever_start(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    111\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name(),\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    117\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/retrievers/ensemble.py:222\u001b[0m, in \u001b[0;36mEnsembleRetriever.rank_fusion\u001b[0;34m(self, query, run_manager, config)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03mRetrieve the results of the retrievers and use rank_fusion_func to get\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mthe final result.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    A list of reranked documents.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Get the results of all retrievers.\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m retriever_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    223\u001b[0m     retriever\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    224\u001b[0m         query,\n\u001b[1;32m    225\u001b[0m         patch_config(\n\u001b[1;32m    226\u001b[0m             config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretriever_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m         ),\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrievers)\n\u001b[1;32m    230\u001b[0m ]\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Enforce that retrieved docs are Documents for each list in retriever_docs\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(retriever_docs)):\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain/retrievers/ensemble.py:223\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03mRetrieve the results of the retrievers and use rank_fusion_func to get\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mthe final result.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    A list of reranked documents.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Get the results of all retrievers.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m retriever_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretriever_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrievers)\n\u001b[1;32m    230\u001b[0m ]\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Enforce that retrieved docs are Documents for each list in retriever_docs\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(retriever_docs)):\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/retrievers.py:258\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 258\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:1079\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1077\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs \u001b[38;5;241m|\u001b[39m kwargs\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1079\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1081\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m   1083\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[1;32m   1084\u001b[0m         )\n\u001b[1;32m   1085\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:350\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    335\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:440\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 440\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__query_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/utils/utils.py:54\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:157\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[0;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/chromadb/api/models/Collection.py:219\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m query_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_query_request(\n\u001b[1;32m    209\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[1;32m    210\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    217\u001b[0m )\n\u001b[0;32m--> 219\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_query_response(\n\u001b[1;32m    231\u001b[0m     response\u001b[38;5;241m=\u001b[39mquery_results, include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    232\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/chromadb/api/fastapi.py:610\u001b[0m, in \u001b[0;36mFastAPI._query\u001b[0;34m(self, collection_id, query_embeddings, n_results, where, where_document, include, tenant, database)\u001b[0m\n\u001b[1;32m    607\u001b[0m filtered_include \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    609\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the nearest neighbors of a single embedding\"\"\"\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m resp_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tenants/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtenant\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/databases/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatabase\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcollection_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/query\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_np_embeddings_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_include\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\n\u001b[1;32m    625\u001b[0m     ids\u001b[38;5;241m=\u001b[39mresp_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    626\u001b[0m     distances\u001b[38;5;241m=\u001b[39mresp_json\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m     included\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    633\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/chromadb/api/fastapi.py:106\u001b[0m, in \u001b[0;36mFastAPI._make_request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_url \u001b[38;5;241m+\u001b[39m escaped_path\n\u001b[1;32m    105\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcast(Any, kwargs))\n\u001b[0;32m--> 106\u001b[0m \u001b[43mBaseHTTPClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_chroma_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m orjson\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/chromadb/api/base_http_client.py:96\u001b[0m, in \u001b[0;36mBaseHTTPClient._raise_chroma_error\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chroma_error:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m chroma_error\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Collection expecting embedding with dimension of 384, got 1536"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# query = resume_text\n",
    "query = f\"\"\"\n",
    "[이력서]\n",
    "{resume_text}\n",
    "\n",
    "[자기소개서]\n",
    "{cover_letter_text}\n",
    "\n",
    "[포트폴리오]\n",
    "{popol_text}\n",
    "\"\"\"\n",
    "response = hybrid_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[hybrid_retriever]\")\n",
    "for doc in response:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c99c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 인재매칭 AI 어시스턴트입니다. 사용자 이력서에 기반하여 채용공고를 5개 추천해주세요.\n",
    "    \n",
    "    - 반드시 이력서에 기반할 것.\n",
    "    - 출력 시 채용공고의 양식을 사용할 것.\n",
    "    - 출력 시 지역은 상세하게 출력 할 것.\n",
    "    - 채용공고 추천 이유를 한줄로 설명할 것.         \n",
    "    - 같은 공고 번호가 중복될 경우 단 1개만 추천할 것.                  \n",
    "    - 채용공고 전체 내용을 기반하여 분석할 것. 제목만 보고 판단하지 말 것.\n",
    "    - page_content의 전체 텍스트를 기준으로 판단할 것.\n",
    "\n",
    "    #이력서: \n",
    "    {question} \n",
    "    #채용공고: \n",
    "    {context} \n",
    "\n",
    "    #출력형태\n",
    "    - 기업명, 공고명, [경력]\n",
    "    - 직무, 지역 \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=1)\n",
    "\n",
    "hybrid_chain = (\n",
    "    {\"context\": hybrid_retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "    #- 추천된 [채용공고]와 [이력서]를 참고하여 각 공고 별로 예상 면접 질문 5개를 만들 것.\n",
    "    #    - 면접 질문 유형은 아래와 같이 출력할 것.\n",
    "    #    - 1개 회사와 관련된 질문\n",
    "    #    - 2개 인적성 면접\n",
    "    #    - 2개 기술/역량 면접\n",
    "    #- 면접 질문은 웹 검색을 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79001414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- (주)유니와이즈솔루션즈, 연구소_AI 교육 정부 과제 연구원_경력\n",
      "  - 직무: ['데이터분석가', '데이터엔지니어', '데이터마이닝', '데이터시각화', '모델링'], 지역: 서울 강남구\n",
      "  - 추천 이유: AI 및 데이터 분석 관련 실무 경험과 Python 및 AI 프레임워크 지식이 요구되는 직무로, 사용자의 경력과 기술 스택과 잘 맞습니다.\n",
      "\n",
      "- (주)씨엘모빌리티, [강남] AI 연구소 개발 연구원 채용 (상시)\n",
      "  - 직무: ['딥러닝', '머신러닝', '연구원'], 지역: 서울 강남구 외\n",
      "  - 추천 이유: 딥러닝과 머신러닝 분야에 대한 깊은 이해와 경험이 요구되며, 사용자의 프로젝트 경험과 일치합니다.\n",
      "\n",
      "- (주)크랜베리, [경력] 파이썬 개발자 채용\n",
      "  - 직무: ['데이터분석가', '데이터엔지니어', '백엔드/서버개발', '앱개발', '웹개발'], 지역: 서울 금천구 외\n",
      "  - 추천 이유: Python과 AI 모델 운영 경험이 요구되며, 사용자의 기술과 경력을 효과적으로 활용할 수 있습니다.\n",
      "\n",
      "- (주)코난테크놀로지, 강화학습 개발자 채용\n",
      "  - 직무: ['딥러닝', '머신러닝', '모델링'], 지역: 서울 서초구\n",
      "  - 추천 이유: 파이썬과 강화학습 모델 개발 경험이 요구되며, 사용자의 학력과 프로젝트 경험이 이를 뒷받침합니다.\n",
      "\n",
      "- 한국과학기술연구원, 2025년 3월 연수직(연구인턴) 공개채용\n",
      "  - 직무: ['머신러닝', '모델링', '자율주행', '컴퓨터비전', 'AI(인공지능)'], 지역: 서울 성북구 외\n",
      "  - 추천 이유: 머신러닝과 AI 프로젝트 경험이 요구되며, 이는 사용자의 학력 및 프로젝트 경험과 잘 부합합니다.\n"
     ]
    }
   ],
   "source": [
    "response = hybrid_chain.invoke(resume_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a4a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 채용공고 추천 목록\n",
      "\n",
      "1. **기업명**: (주)크랜베리  \n",
      "   **공고명**: [경력] 파이썬 개발자 채용  \n",
      "   **직무**: 데이터분석가, 데이터엔지니어, 백엔드/서버개발, 앱개발, 웹개발  \n",
      "   **지역**: 서울 금천구 가산디지털1로 225 에이스 가산 포휴 316~318호  \n",
      "\n",
      "   **추천 이유**: 홍길동님의 파이썬 및 AI 모델 개발 경험이 회사의 요구사항에 부합합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)크랜베리의 AI 운영 시스템 개발에 어떻게 기여할 수 있을까요?\n",
      "   - **인적성 면접**:\n",
      "     1. 자신의 문제 해결 능력을 보여준 경험에 대해 이야기해 주세요.\n",
      "     2. 팀 내의 갈등을 해결한 경험이 있습니까? 어떻게 해결했나요?\n",
      "   - **기술/역량 면접**:\n",
      "     1. 파이썬을 사용하여 개발한 프로젝트가 있다면 설명해 주세요.\n",
      "     2. 대규모 데이터 핸들링 경험에 대해 설명해 주세요.\n",
      "\n",
      "2. **기업명**: (주)유니와이즈솔루션즈  \n",
      "   **공고명**: 연구소_AI 교육 정부 과제 연구원_경력  \n",
      "   **직무**: 데이터분석가, 데이터엔지니어, 데이터마이닝, 데이터시각화, 모델링  \n",
      "   **지역**: 서울 강남구 광평로 295, 2층  \n",
      "\n",
      "   **추천 이유**: 데이터 분석 및 AI 프레임워크에 대한 지식이 요구되는 직무로서, 홍길동님의 기술 스택과 일치합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)유니와이즈솔루션즈에서 AI 교육 연구를 진행할 때 중점을 두고 싶은 부분은 무엇인가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 데이터 분석에서 가장 중요한 요소는 무엇이라고 생각하나요?\n",
      "     2. 본인의 장단점에 대해 설명해 주세요.\n",
      "   - **기술/역량 면접**:\n",
      "     1. TensorFlow나 PyTorch를 활용한 프로젝트 경험이 있나요? 설명해 주세요.\n",
      "     2. AI 모델의 최적화 작업을 수행한 경험이 있다면 설명해 주세요.\n",
      "\n",
      "3. **기업명**: (주)씨엘모빌리티  \n",
      "   **공고명**: [강남] AI 연구소 개발 연구원 채용 (상시)  \n",
      "   **직무**: 딥러닝, 머신러닝, 연구원  \n",
      "   **지역**: 서울 강남구  \n",
      "\n",
      "   **추천 이유**: 딥러닝 및 머신러닝 관련 프로젝트 경험이 많은 홍길동님에게 적합한 직무입니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)씨엘모빌리티의 연구소에서 어떤 연구를 진행하고 싶으신가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 스트레스를 어떻게 관리하나요?\n",
      "     2. 커뮤니케이션 능력을 발휘한 경험을 설명해 주세요.\n",
      "   - **기술/역량 면접**:\n",
      "     1. 딥러닝 모델을 개발한 경험에 대해 설명해 주세요.\n",
      "     2. 머신러닝에서 모델의 성능을 평가하는 방법에 대해 설명해 주세요.\n",
      "\n",
      "4. **기업명**: 한국과학기술연구원  \n",
      "   **공고명**: 2025년 3월 연수직(연구인턴) 공개채용  \n",
      "   **직무**: 머신러닝, 모델링, 자율주행, 컴퓨터비전, AI(인공지능)  \n",
      "   **지역**: 서울 성북구  \n",
      "\n",
      "   **추천 이유**: 홍길동님의 학력과 프로젝트 경험이 인턴십 프로그램에 적합합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: 한국과학기술연구원의 인턴십에서 배우고 싶은 것은 무엇인가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 실패에서 배운 경험을 이야기해 주세요.\n",
      "     2. 여러 업무를 동시에 처리한 경험이 있나요? 어떻게 처리했나요?\n",
      "   - **기술/역량 면접**:\n",
      "     1. 머신러닝 프로젝트의 전반적인 과정에 대해 설명해 주세요.\n",
      "     2. 데이터 전처리의 중요성에 대해 설명해 주세요.\n",
      "\n",
      "5. **기업명**: (주)코난테크놀로지  \n",
      "   **공고명**: 강화학습 개발자 채용  \n",
      "   **직무**: 딥러닝, 머신러닝, 모델링  \n",
      "   **지역**: 서울 서초구 강남대로 327 대륭서초타워 9층  \n",
      "\n",
      "   **추천 이유**: 강화학습 및 파이썬 관련 경험이 회사의 요구사항과 부합합니다.  \n",
      "   **예상 면접 질문**:\n",
      "   - **회사 관련**: (주)코난테크놀로지에서 강화학습을 활용하여 어떤 혁신을 이루고 싶으신가요?\n",
      "   - **인적성 면접**:\n",
      "     1. 창의력을 발휘한 경험이 있다면 이야기해 주세요.\n",
      "     2. 본인의 가장 큰 실패는 무엇이었나요?\n",
      "   - **기술/역량 면접**:\n",
      "     1. 강화학습을 활용한 프로젝트 경험에 대해 설명해 주세요.\n",
      "     2. Docker와 같은 컨테이너 도구를 사용한 경험이 있나요? 설명해 주세요."
     ]
    }
   ],
   "source": [
    "for chunk in hybrid_chain.stream(resume_text):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adf871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4600b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
