import streamlit as st
from sidebar import show_sidebar
import time
import cv2
import tempfile
import openai
import os
from dotenv import load_dotenv


load_dotenv()
# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.environ.get('OPENAI_API_KEY')
client = openai.OpenAI()

def set_session_state():
    if "webcam_bool" not in st.session_state:
        st.session_state.webcam_bool = False

    if "audio_bool" not in st.session_state:
        st.session_state.audio_bool = False

    if "speaker_bool" not in st.session_state:
        st.session_state.speaker_bool = False

    if "test_count" not in st.session_state:
        st.session_state.test_count = 0


def reset_session_state():
    st.session_state.webcam_bool = False
    st.session_state.audio_bool = Fals
    st.session_state.speaker_bool = False
    st.session_state.test_count = 0

set_session_state()

# ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(__file__))  # pages ìƒìœ„ í´ë” ê¸°ì¤€
img_webcam = os.path.join(BASE_DIR, "images", "webcam_test.png")
img_mic = os.path.join(BASE_DIR, "images", "mic_test.png")
img_speaker = os.path.join(BASE_DIR, "images", "speaker_test.png")

def show_done_image(image_path):
    st.image(image_path, width=150)

def main():
    st.set_page_config(layout="wide")
    show_sidebar()
    # í˜ì´ì§€ ìƒë‹¨ ê³µë°± ì œê±° markdown
    st.markdown(
        """
            <style>
                    .stAppHeader {
                        background-color: rgba(255, 255, 255, 0.0);  /* Transparent background */
                        visibility: visible;  /* Ensure the header is visible */
                    }

                .block-container {
                        padding-top: 1rem;
                        padding-bottom: 0rem;
                        padding-left: 5rem;
                        padding-right: 5rem;
                    }
                    [data-testid="stSidebarNav"] {display: none;}
            </style>
            """,
        unsafe_allow_html=True,
    )

    st.title("ì¥ë¹„ í…ŒìŠ¤íŠ¸")

    webcam_placeholder = st.empty()
    webcam = cv2.VideoCapture(0, cv2.CAP_V4L2)

    if st.session_state.webcam_bool == False:
        webcam_placeholder.write('1. ì›¹ìº  í…ŒìŠ¤íŠ¸ :no_entry_sign:')

        if not webcam.isOpened():
            webcam_placeholder.write('âŒ ì›¹ìº ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    else:
        webcam_placeholder.write('1. ì›¹ìº  í…ŒìŠ¤íŠ¸')
        show_done_image(img_webcam)
   
    def set_webcam_bool(webcam, content_placeholder):
        webcam.release()
        cv2.destroyAllWindows()
        content_placeholder.empty()
        webcam_placeholder.write('1. ì›¹ìº  í…ŒìŠ¤íŠ¸')
        st.session_state.webcam_bool = True


    if st.session_state.webcam_bool == False:
        # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ UI ìš”ì†Œë¥¼ ë¹„ìš°ê¸° ìœ„í•œ empty() ê°ì²´
        content_placeholder = st.empty()
        
        with content_placeholder.container(border=True if webcam.isOpened() else False):
            frame_window = st.image([])

            webcam.set(cv2.CAP_PROP_FPS, 10)  # FPS ì†ì„± ì„¤ì • (ì§€ì›í•˜ëŠ” ê²½ìš°)
            webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 400)
            webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 280)

            frame_count = 0
            stop_button_pressed = st.button("ì¢…ë£Œ", on_click=set_webcam_bool, args=(webcam, content_placeholder))
            #if stop_button_pressed:
                #webcam.release()
                #content_placeholder.empty()  # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ìš”ì†Œ ì‚­ì œ
                #st.session_state.test_count = st.session_state.test_count + 1
                
            #stop_button_pressed = st.button("ì¢…ë£Œ")
            while webcam.isOpened():
                ret, frame = webcam.read()
                if not ret:
                    st.error("ì¹´ë©”ë¼ì—ì„œ ì˜ìƒì„ ì½ì–´ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break

                frame_count += 1
                # 3í”„ë ˆì„ ì¤‘ 1í”„ë ˆì„ë§Œ ì²˜ë¦¬í•˜ì—¬ ë¶€í•˜ ì¤„ì´ê¸°
                if frame_count % 3 != 0:
                    continue

                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_window.image(frame)
                time.sleep(0.1)  # ë£¨í”„ ì§€ì—° ì¶”ê°€
                if stop_button_pressed:
                    break
        
    audio()


def audio():
    audio_placeholder = st.empty()
    if st.session_state.audio_bool == False:
        audio_placeholder.write("2. ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ :no_entry_sign:")
    else:
        audio_placeholder.write("2. ë§ˆì´í¬ í…ŒìŠ¤íŠ¸")

    
    audio_container = st.empty()
    if st.session_state.audio_bool == False:
        with audio_container.container():
            audio_value = st.audio_input("")

            if audio_value:
                # ì„ì‹œ íŒŒì¼ì— ì˜¤ë””ì˜¤ ì €ì¥
                tmp_path = ''
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_value.getbuffer())
                    tmp_path = tmp.name
               
                transcript = ''
                # OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì‚¬ ìˆ˜í–‰
                with open(tmp_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="ko",
                        response_format="text",
                        temperature=0.0
                    )
                        
                st.write(transcript)
                # st.write(audio_value)
                # audio_data = st.audio(audio_value)

                if len(transcript) > 0:
                    if st.session_state.audio_bool == False:
                        audio_placeholder.write("2. ë§ˆì´í¬ í…ŒìŠ¤íŠ¸")
                    st.session_state.audio_bool = True
                    audio_container.empty()

    if st.session_state.audio_bool:
        show_done_image(img_mic)
        speak_test()

def speak_test():
    speaker_placeholder = st.empty()
    
    if st.session_state.speaker_bool == False:
        speaker_placeholder.write("3. ìŠ¤í”¼ì»¤ í…ŒìŠ¤íŠ¸ :no_entry_sign:")
    else:
        speaker_placeholder.write("3. ìŠ¤í”¼ì»¤ í…ŒìŠ¤íŠ¸")
    speaker_container = st.empty()
    if st.session_state.speaker_bool == False:
        with speaker_container.container():
            response = client.audio.speech.create(
                model="tts-1",
                input="ìŠ¤í”¼ì»¤ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. ìŠ¤í”¼ì»¤ê°€ ì¼œì ¸ìˆìœ¼ë©´ í™•ì¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.",
                voice="alloy",
                response_format="mp3",
                speed=1.1,
            )
            
            st.audio(response.content)

            if st.button('í™•ì¸'):
                if st.session_state.speaker_bool == False:
                    speaker_placeholder.write("3. ìŠ¤í”¼ì»¤ í…ŒìŠ¤íŠ¸")
                st.session_state.speaker_bool = True
                speaker_container.empty()

    if st.session_state.speaker_bool:
        show_done_image(img_speaker)
if __name__ == "__main__":
    #st.switch_page("pages/mng_2.py")
    main()
    
    
    if st.session_state.webcam_bool == True  \
        and st.session_state.audio_bool == True \
        and st.session_state.speaker_bool == True:

        st.success("âœ… ëª¨ë“  ì¥ë¹„ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if st.button('ğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ â†’ ë©´ì ‘ ì‹œì‘', key="start_interview"):
            time.sleep(1)
            st.switch_page("pages/itv.py")
